{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen von der CSV und aufspalten auf Religion und Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"20 newsgroups/20newsgroups.csv\", on_bad_lines='skip', sep=';')\n",
    "data.dropna()\n",
    "data = data.iloc[:,1:3]\n",
    "\n",
    "dataSplit = data.drop(data[data[\"group\"] == 1 ].index)\n",
    "dataSplit = dataSplit.drop(data[data[\"group\"] == 2 ].index)\n",
    "dataAth = data.drop(data[data[\"group\"] != 0 ].index)\n",
    "dataReli = data.drop(data[data[\"group\"] != 3 ].index)\n",
    "\n",
    "dataSpace = data.drop(data[data[\"group\"] != 2 ].index)\n",
    "dataGraphics = data.drop(data[data[\"group\"] != 1 ].index)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Freq_words Generierung                                                                        \n",
    "Änderung zu vorherigem Code: \n",
    "- toke.text.strip entfernt leere oder Whitespace-only Einträge\n",
    "- regex entfernt alle nicht Zahlen oder Buchstaben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqAth = Counter()\n",
    "for text in dataAth[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqAth.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqReli = Counter()\n",
    "for text in dataReli[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqReli.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqSpace = Counter()\n",
    "for text in dataSpace[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqSpace.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqGraphics = Counter()\n",
    "for text in dataGraphics[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqGraphics.update(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nt', 704), ('god', 586)]\n",
      "704\n"
     ]
    }
   ],
   "source": [
    "print(word_freqReli.most_common(2))\n",
    "print(word_freqReli.get(\"nt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generierung der neuen most_common_words:\n",
    "Notwendig sind für 500 Worte:\n",
    "- Reli: \n",
    "- Ath: \n",
    "- Graphics:\n",
    "- Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faktor = 1\n",
    "faktorRA = 3\n",
    "words = 700\n",
    "\n",
    "freqList_Reli = []\n",
    "for word, freq in word_freqReli.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Reli) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktorRA * freqAth) and \n",
    "        (freqSpace is None or freq >= faktorRA * freqSpace) and \n",
    "        (freqGraphics is None or freq >= faktorRA * freqGraphics)):\n",
    "        freqList_Reli.append(word)\n",
    "\n",
    "\n",
    "freqList_Ath = []\n",
    "for word, freq in word_freqAth.most_common(10000):\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Ath) >= words:\n",
    "        break\n",
    "    if ((freqReli is None or freq >=faktorRA * freqReli) and \n",
    "        (freqSpace is None or freq >= faktorRA * freqSpace) and \n",
    "        (freqGraphics is None or freq >= faktorRA * freqGraphics)):\n",
    "        freqList_Ath.append(word)\n",
    "\n",
    "freqList_Space = []\n",
    "for word, freq in word_freqSpace.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Space) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktor * freqAth) and \n",
    "        (freqGraphics is None or freq >= faktor * freqGraphics) and \n",
    "        (freqReli is None or freq >= faktor * freqReli)):\n",
    "        freqList_Space.append(word)\n",
    "\n",
    "freqList_Graphics = []\n",
    "for word, freq in word_freqGraphics.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    if len(freqList_Graphics) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktor * freqAth) and \n",
    "        (freqSpace is None or freq >= faktor * freqSpace) and \n",
    "        (freqReli is None or freq >= faktor * freqReli)):\n",
    "        freqList_Graphics.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datei anlegen und befüllen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atheists</th>\n",
       "      <th>argument</th>\n",
       "      <th>atheism</th>\n",
       "      <th>atheist</th>\n",
       "      <th>islam</th>\n",
       "      <th>exist</th>\n",
       "      <th>theism</th>\n",
       "      <th>quran</th>\n",
       "      <th>islamic</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>...</th>\n",
       "      <th>increases</th>\n",
       "      <th>topic</th>\n",
       "      <th>forces</th>\n",
       "      <th>batse</th>\n",
       "      <th>consideration</th>\n",
       "      <th>physicist</th>\n",
       "      <th>distances</th>\n",
       "      <th>fahrenheit</th>\n",
       "      <th>relatively</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [atheists, argument, atheism, atheist, islam, exist, theism, quran, islamic, fallacy, exists, arguments, altatheism, statements, theists, logic, natural, muslim, rushdie, morals, bobby, social, rational, logical, gd, deletion, liar, premise, sea, debate, assertion, weak, irrational, behaviour, premises, james, hypothesis, br, blew, beauchaine, bobbeviceicotekcom, aa, queens, bronx, sank, manhattan, argumentum, motivated, analogy, isaiah, psalm, dogma, fanatism, imply, fish, hussein, rh, americans, proposition, motto, pink, khomeini, razor, matthews, lunatic, maddi, fatwa, posters, philosophical, benefactor, viewpoint, brains, phrase, logically, mozumder, disease, cruel, spoken, enviroleague, mom, bcci, wars, absurd, penalty, supernatural, genetic, deletions, mouth, nonexistence, arrogant, bombing, conscious, iraq, liberty, invalid, drawn, probability, mythology, iraqi, evolve, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2801 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqList = freqList_Ath+freqList_Reli+freqList_Graphics+freqList_Space+[\"groupID\"]\n",
    "freqListData = pd.DataFrame(columns=freqList)\n",
    "freqListData.to_csv(\"20newsgroups_freqList.csv\", index=False)\n",
    "freqListData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     neue_zeile_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([haeufigkeiten])\n\u001b[0;32m     11\u001b[0m     neue_zeile_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m     freqListData \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfreqListData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneue_zeile_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m freqListData\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20newsgroups_freqList.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m freqListData\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32md:\\JonaLissner\\conda\\envs\\studiumKI\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\JonaLissner\\conda\\envs\\studiumKI\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32md:\\JonaLissner\\conda\\envs\\studiumKI\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "for index, row in data.iterrows():\n",
    "    text = str(row['text'])\n",
    "    group = str(row['group'])\n",
    "    doc = nlp(text)\n",
    "    count_in_freqList = Counter(token.text.lower() for token in doc if token.is_alpha)\n",
    "\n",
    "    haeufigkeiten = {word: count_in_freqList.get(word, 0) for word in freqList}\n",
    "    haeufigkeiten['groupID'] = group\n",
    "    # Erstelle ein neues DataFrame aus der Zeile der Häufigkeiten\n",
    "    neue_zeile_df = pd.DataFrame([haeufigkeiten])\n",
    "    neue_zeile_df.reset_index(drop=True, inplace=True)\n",
    "    freqListData = pd.concat([freqListData, neue_zeile_df], ignore_index=True)\n",
    "\n",
    "freqListData.to_csv(\"20newsgroups_freqList.csv\", index=False)\n",
    "freqListData.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiumKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
