{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                                    Klasse zum Training eines DecissionTreeClassifiers:                                                                                                                                        \n",
    "__init__ \n",
    "- Methode ist der Konstruktor der Klasse:\n",
    "- alle Parameter mit \"=\" sind nicht verpflichtend, also ist es nur path zur csv-Datei                                                                                                                                                                                                                               \n",
    "- ohne Angabe des Schlüsselwortes muss die Reihenfolge eingehalten werden, mit entsprechend nicht            \n",
    "                                                                                                                                                                                                     \n",
    "__data__:\n",
    "- Methode kann man nicht von außen aufruen, das liegt an den __ quasi das private in Python     \n",
    "\n",
    "min_sample_split:\n",
    "- Gibt für festes max_depth den besten Wert zurück, ohne den besten der Klasse zu überschreiben\n",
    "\n",
    "train:\n",
    "- übernimmt die Kombination der 3 bisher vorhandenen Einstellungen, jede Kombination wird getestet\n",
    "- für jede Kombination wird f-score, precission und recall in die letzte Spalte eines numby arrays geschrieben\n",
    "- nach dem Durchlaufen wird die beste Kombination ermittelt und in die Klasse geschrieben + ausgegegen\n",
    "                                                                                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainMan:\n",
    "    def __init__(self, path, \n",
    "                 max_depthVal=None, max_depthMax=200, max_depthMin=0, \n",
    "                 min_sample_splitVal = 2, min_sample_splitMax=10, min_sample_splitMin=2, \n",
    "                 clf=None, criterionVal=\"entropy\"):\n",
    "        self.path = path\n",
    "        self.trainList = self.__data()\n",
    "        self.max_depthVal = max_depthVal\n",
    "        self.max_depthMax = max_depthMax\n",
    "        self.max_depthMin=max_depthMin\n",
    "        self.min_sample_splitMax = min_sample_splitMax\n",
    "        self.min_sample_splitMin = min_sample_splitMin\n",
    "        self.min_sample_splitVal = min_sample_splitVal\n",
    "        self.clf = clf\n",
    "        self.criterionVal = criterionVal\n",
    "        self.results = np.empty((3, max_depthMax-max_depthMin, min_sample_splitMax-min_sample_splitMin, 3))\n",
    "    def __data(self):\n",
    "        self.data = pd.read_csv(self.path)\n",
    "        columnsLength = self.data.shape[1]-1\n",
    "        X = self.data.iloc[:,0:columnsLength]\n",
    "        y = self.data[[\"groupID\"]].values.ravel()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n",
    "        return [X_train, X_test, y_train, y_test]\n",
    "    def out(self):\n",
    "        if(self.clf == None):\n",
    "            print(\"Modell ohne Parameter wird angelegt, da keines vorhanden:\")\n",
    "            self.clf = DecisionTreeClassifier(random_state=42)\n",
    "            self.clf = self.clf.fit(self.trainList[0], self.trainList[2])\n",
    "        predict = self.clf.predict(self.trainList[1])\n",
    "        report = classification_report(self.trainList[3], predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "        #print(report)\n",
    "        #print(\"F-Score: \",f1_score(predict, self.trainList[3], average='macro'))\n",
    "        #print(\"Precision: \",precision_score(predict, self.trainList[3], average='macro'))\n",
    "        #print(\"Recall: \",recall_score(predict, self.trainList[3], average='macro'))\n",
    "        return f1_score(predict, self.trainList[3], average='macro'), precision_score(predict, self.trainList[3], average='macro'), recall_score(predict, self.trainList[3], average='macro')\n",
    "    def max_depth(self, min, max):\n",
    "        self.max_depthMax = max\n",
    "        self.max_depthMin = min\n",
    "        f = 0\n",
    "        for i in range(self.max_depthMax):\n",
    "            if(i<self.max_depthMin):\n",
    "                continue\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, max_depth=i, min_samples_split=self.min_sample_splitVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.max_depthVal = i\n",
    "                self.clf =  DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, max_depth=i, min_samples_split=self.min_sample_splitVal)\n",
    "                self.clf = self.clf.fit(self.trainList[0], self.trainList[2])      \n",
    "        return self.max_depthVal\n",
    "    def min_sample_split(self):\n",
    "        f = 0\n",
    "        for i in range(self.min_sample_splitMax):\n",
    "            if(i<self.min_sample_splitMin):\n",
    "                continue\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, min_samples_split=i, max_depth=self.max_depthVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.min_sample_splitVal = i    \n",
    "        return self.min_sample_splitVal\n",
    "    def criterion(self):\n",
    "        criterionList = {\"entropy\", \"log_loss\", \"gini\"}\n",
    "        f = 0\n",
    "        for criterion in criterionList:\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=self.min_sample_splitVal, max_depth=self.max_depthVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.criterionVal = criterion\n",
    "                self.clf =  DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=self.min_sample_splitVal, max_depth=self.max_depthVal)\n",
    "                self.clf = self.clf.fit(self.trainList[0], self.trainList[2])\n",
    "        return self.criterionVal  \n",
    "    def train(self):\n",
    "        criterionList = {\"entropy\", \"log_loss\", \"gini\"}\n",
    "        for criterion in criterionList:\n",
    "            if (criterion == \"entropy\"):\n",
    "                index = 0\n",
    "            elif (criterion==\"log_loss\"):\n",
    "                index = 1\n",
    "            else:\n",
    "                index = 2\n",
    "            for depth in range(self.max_depthMax):\n",
    "                if(depth < self.max_depthMin):\n",
    "                    continue\n",
    "                for min_split in range (self.min_sample_splitMax):\n",
    "                    if (min_split<self.min_sample_splitMin):\n",
    "                        continue\n",
    "                    clf = DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=min_split, max_depth=depth)\n",
    "                    clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "                    predict = clf.predict(self.trainList[1])\n",
    "                    print(str(index)+\"|\"+str(depth)+\"|\"+str(min_split))\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 0] = f1_score(predict, self.trainList[3], average='macro')\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 1] = precision_score(predict, self.trainList[3], average='macro')\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 2] = recall_score(predict, self.trainList[3], average='macro')\n",
    "        index = np.unravel_index(np.argmax(self.results[:, :, :, 0]), self.results[:, :, :, 0].shape)\n",
    "        if (index[0] == 0):\n",
    "            self.criterionVal = \"entropy\"\n",
    "        elif (index[0]==1):\n",
    "            self.criterionVal = \"log_loss\"\n",
    "        else:\n",
    "            self.criterionVal = \"gini\"\n",
    "        self.max_depthVal = index[1]+self.max_depthMin\n",
    "        self.min_sample_splitVal = index[2]+self.min_sample_splitMin\n",
    "        print(self.criterionVal+\"|\"+str(self.max_depthVal)+\"|\"+str(self.min_sample_splitVal))\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeit für folgende Daten:\n",
    "- \"20newsgroups_processed.csv\"\n",
    "- max_depthMin=1\n",
    "- max_depthMax=200\n",
    "- min_sample_splitMin=2\n",
    "- min_sample_splitMax=15                                                                                                                                                                                                                                                \n",
    "--> 30min                                                                                                                                                                                                                                                               \n",
    "--> Beste Kombination log_loss 100 7                                                                                                                                                                                                                                    \n",
    "* F-Score:  0.6213630378339723\n",
    "* Precision:  0.6213414304805736\n",
    "* Recall:  0.6372077089409636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTree = trainMan(\"csv/CSV Processed/20newsgroups_processed_1000.csv\")\n",
    "testTree.max_depth(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy|191|2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.51      0.54       159\n",
      "    Graphics       0.72      0.70      0.71       194\n",
      "       Space       0.67      0.72      0.69       197\n",
      "    Religion       0.46      0.48      0.47       125\n",
      "\n",
      "    accuracy                           0.62       675\n",
      "   macro avg       0.60      0.60      0.60       675\n",
      "weighted avg       0.62      0.62      0.62       675\n",
      "\n",
      "F-Score:  0.6024746631764062\n",
      "Precision:  0.6028192682100798\n",
      "Recall:  0.6036299388987386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6024746631764062, 0.6028192682100798, 0.6036299388987386)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testTree.criterionVal+\"|\"+str(testTree.max_depthVal)+\"|\"+str(testTree.min_sample_splitVal))\n",
    "testTree.out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Beispiel-Daten\n",
    "log_loss = {\n",
    "    1: 0.23336718067395565,\n",
    "2: 0.3059842416150827,\n",
    "3: 0.32464710961005,\n",
    "4: 0.3406122770736125,\n",
    "5: 0.3609512410197733,\n",
    "6: 0.41744774061369055,\n",
    "7: 0.4039242499408174,\n",
    "8: 0.421674353141403,\n",
    "9: 0.42163328239929604,\n",
    "10: 0.4379553171678973,\n",
    "11: 0.4385500074245342,\n",
    "12: 0.44931475431879775,\n",
    "13: 0.4850885478002036,\n",
    "14: 0.48565821046858204,\n",
    "15: 0.48938056853619344,\n",
    "16: 0.4852116489054656,\n",
    "17: 0.49442217285581946,\n",
    "18: 0.5193106243028843,\n",
    "19: 0.4970725732859358,\n",
    "20: 0.5426763555186807,\n",
    "21: 0.5295757237578113,\n",
    "22: 0.5312719460685801,\n",
    "23: 0.5538392457324646,\n",
    "24: 0.5611717987950305,\n",
    "25: 0.5591716783173304,\n",
    "26: 0.5529788906816302,\n",
    "27: 0.5657146574955366,\n",
    "28: 0.5733614693886971,\n",
    "29: 0.5685551879567686,\n",
    "30: 0.5695758598516925,\n",
    "31: 0.5776775184478992,\n",
    "32: 0.5733020663705998,\n",
    "33: 0.5730514093227609,\n",
    "34: 0.5744467282289409,\n",
    "35: 0.5847935580303225,\n",
    "36: 0.5825166010359958,\n",
    "37: 0.5915501473180311,\n",
    "38: 0.5916836437132416,\n",
    "39: 0.5903869330968923,\n",
    "40: 0.586785641218631,\n",
    "41: 0.5964181874587711,\n",
    "42: 0.5940086078621366,\n",
    "43: 0.5975877812120938,\n",
    "44: 0.5987286899151394,\n",
    "45: 0.5881407716344306,\n",
    "46: 0.5931551484399267,\n",
    "47: 0.6017901316027017,\n",
    "48: 0.596032475490196,\n",
    "49: 0.5963739520063417,\n",
    "50: 0.5994754858626586,\n",
    "51: 0.598537111753932,\n",
    "52: 0.6053035510203342,\n",
    "53: 0.5968349124823885,\n",
    "54: 0.5983983553627145,\n",
    "55: 0.6048762988958766,\n",
    "56: 0.6001853093739362,\n",
    "57: 0.5935411708060033,\n",
    "58: 0.604691486459877,\n",
    "59: 0.6055622464685265,\n",
    "60: 0.5982424940377572,\n",
    "61: 0.6050468941529717,\n",
    "62: 0.6083365950418325,\n",
    "63: 0.5995547134163781,\n",
    "64: 0.600457955355484,\n",
    "65: 0.6057321888175319,\n",
    "66: 0.6117885390315883,\n",
    "67: 0.61287665752338,\n",
    "68: 0.6103417334748892,\n",
    "69: 0.6087206952600476,\n",
    "70: 0.6114852780721454,\n",
    "71: 0.6127610628618694,\n",
    "72: 0.6060521452359685,\n",
    "73: 0.6092506741490823,\n",
    "74: 0.6060933720949063,\n",
    "75: 0.6106858485581815,\n",
    "76: 0.6074416602742174,\n",
    "77: 0.6058147826323819,\n",
    "78: 0.6117037218070851,\n",
    "79: 0.6204333837296909,\n",
    "80: 0.6187024125520477,\n",
    "81: 0.6097091864719536,\n",
    "82: 0.611870336773354,\n",
    "83: 0.612855262665073,\n",
    "84: 0.6118609365200888,\n",
    "85: 0.6145425680337079,\n",
    "86: 0.611883700329785,\n",
    "87: 0.6176802425560703,\n",
    "88: 0.6103847502665318,\n",
    "89: 0.6112465085820501,\n",
    "90: 0.6123303341749943,\n",
    "91: 0.6115841100544527,\n",
    "92: 0.6121423575986913,\n",
    "93: 0.6096765139858922,\n",
    "94: 0.6165044876388523,\n",
    "95: 0.61250780077023,\n",
    "96: 0.6142800408173401,\n",
    "97: 0.6072685215437107,\n",
    "98: 0.6128597651700951,\n",
    "99: 0.6172961261939661,\n",
    "100: 0.6213630378339723,\n",
    "101: 0.6064280192470245,\n",
    "102: 0.6096274595347045,\n",
    "103: 0.6141347188869133,\n",
    "104: 0.6147355095622443,\n",
    "105: 0.6159424739577265,\n",
    "106: 0.6173796974205754,\n",
    "107: 0.6180939540100239,\n",
    "108: 0.6115374089512021,\n",
    "109: 0.6115020908765156,\n",
    "110: 0.6200922140912533,\n",
    "111: 0.6181463470200431,\n",
    "112: 0.6097892925635934,\n",
    "113: 0.6046944080977212,\n",
    "114: 0.6147209983797204,\n",
    "115: 0.6056168819148927,\n",
    "116: 0.6077649395080652,\n",
    "117: 0.6109033984683523,\n",
    "118: 0.6124992419149253,\n",
    "119: 0.6083371109933889,\n",
    "120: 0.6105981473906001,\n",
    "121: 0.6109281573504195,\n",
    "122: 0.6071299607531492,\n",
    "123: 0.6140443946528786,\n",
    "124: 0.6084381261558707,\n",
    "125: 0.6038763327210599,\n",
    "126: 0.6038421991180297,\n",
    "127: 0.6069167403595286,\n",
    "128: 0.606588633265506,\n",
    "129: 0.6085711302866873,\n",
    "130: 0.606677153455504,\n",
    "131: 0.6046398046398045,\n",
    "132: 0.6008958170881894,\n",
    "133: 0.6061398015182283,\n",
    "134: 0.6032796614735156,\n",
    "135: 0.5946283080348712,\n",
    "136: 0.5982453339163016,\n",
    "137: 0.5946809674012178,\n",
    "138: 0.589866584670049,\n",
    "139: 0.6005784301447006,\n",
    "140: 0.6005333085632403,\n",
    "141: 0.5959007581869307,\n",
    "142: 0.6076067207215954,\n",
    "143: 0.5936585365853658,\n",
    "144: 0.6032245302342191,\n",
    "145: 0.6009868661049388,\n",
    "146: 0.5975467206199865,\n",
    "147: 0.5957409302788705,\n",
    "148: 0.5954420848457487,\n",
    "149: 0.5944494600975563,\n",
    "150: 0.5937589580152924,\n",
    "151: 0.5939791406583681,\n",
    "152: 0.5994873847961918,\n",
    "153: 0.5967197120235812,\n",
    "154: 0.5995457134457796,\n",
    "155: 0.5987499510351743,\n",
    "156: 0.5990808388533818,\n",
    "157: 0.5988069470212327,\n",
    "158: 0.5942910788906963,\n",
    "159: 0.6038907649652677,\n",
    "160: 0.6071459719866024,\n",
    "161: 0.5958353572337489,\n",
    "162: 0.5962935669241297,\n",
    "163: 0.5965511988011989,\n",
    "164: 0.6016988954326195,\n",
    "165: 0.5988241160850473,\n",
    "166: 0.5984219270613804,\n",
    "167: 0.6007016864040134,\n",
    "168: 0.6079852904041394,\n",
    "169: 0.6055510373354626,\n",
    "170: 0.6019695175602591,\n",
    "171: 0.5966741790189385,\n",
    "172: 0.6003771055887487,\n",
    "173: 0.6006040768650045,\n",
    "174: 0.6040346815958357,\n",
    "175: 0.6075748596921958,\n",
    "176: 0.5952430918503632,\n",
    "177: 0.6004766803374236,\n",
    "178: 0.5962758182714187,\n",
    "179: 0.5996048674322963,\n",
    "180: 0.6017106818986651,\n",
    "181: 0.6023070320387734,\n",
    "182: 0.6017487986437138,\n",
    "183: 0.6043446096672669,\n",
    "184: 0.6041332156658616,\n",
    "185: 0.6025162217039381,\n",
    "186: 0.6045023419703548,\n",
    "187: 0.6027066940664462,\n",
    "188: 0.6006344970744926,\n",
    "189: 0.5988096176462476,\n",
    "190: 0.5984402116349075,\n",
    "191: 0.6010712512169982,\n",
    "192: 0.6044437138437107,\n",
    "193: 0.6039693874703319,\n",
    "194: 0.6014040641477434,\n",
    "195: 0.5998022033176961,\n",
    "196: 0.5998343883539194,\n",
    "197: 0.6045540875182421,\n",
    "198: 0.5974137100397818,\n",
    "199: 0.6037311310651529,\n",
    "200: 0.6001197242475482,\n",
    "\n",
    "}\n",
    "\n",
    "gini = {\n",
    "1: 0.23336718067395565,\n",
    "2: 0.3200979459870673,\n",
    "3: 0.3093029150823828,\n",
    "4: 0.34322106163794186,\n",
    "5: 0.38214023122559704,\n",
    "6: 0.42031302351019556,\n",
    "7: 0.4324490348396976,\n",
    "8: 0.4230617099478968,\n",
    "9: 0.4319310381342155,\n",
    "10: 0.4377103455672076,\n",
    "11: 0.46836023712414143,\n",
    "12: 0.4749436961644866,\n",
    "13: 0.4859083938517436,\n",
    "14: 0.5015249267823588,\n",
    "15: 0.5006519189310606,\n",
    "16: 0.5074318234709068,\n",
    "17: 0.5094455726134242,\n",
    "18: 0.517997751767907,\n",
    "19: 0.515663743496845,\n",
    "20: 0.5167530962422291,\n",
    "21: 0.5352327793632141,\n",
    "22: 0.5382989900299338,\n",
    "23: 0.5404924621896534,\n",
    "24: 0.5349016623107885,\n",
    "25: 0.5417508011030456,\n",
    "26: 0.554982960655875,\n",
    "27: 0.5665521253021806,\n",
    "28: 0.5604842067922949,\n",
    "29: 0.5600662554221579,\n",
    "30: 0.5588966130561001,\n",
    "31: 0.5596485435468487,\n",
    "32: 0.551262008199229,\n",
    "33: 0.5623190670310979,\n",
    "34: 0.5628058772408112,\n",
    "35: 0.565179202404503,\n",
    "36: 0.5661565533104546,\n",
    "37: 0.5636228148771223,\n",
    "38: 0.5734842504021606,\n",
    "39: 0.5697710071814865,\n",
    "40: 0.56755220521692,\n",
    "41: 0.5743907516173001,\n",
    "42: 0.5650097982971635,\n",
    "43: 0.5717258628735259,\n",
    "44: 0.5662090727778417,\n",
    "45: 0.5699516546471232,\n",
    "46: 0.5673353018408409,\n",
    "47: 0.5778996135812069,\n",
    "48: 0.5725569675984421,\n",
    "49: 0.584089126984155,\n",
    "50: 0.5827710459206912,\n",
    "51: 0.5905304974920262,\n",
    "52: 0.5809704368665265,\n",
    "53: 0.5768333086545013,\n",
    "54: 0.580434709145435,\n",
    "55: 0.5715244408962253,\n",
    "56: 0.5819464521280138,\n",
    "57: 0.577520419675914,\n",
    "58: 0.5836768388106416,\n",
    "59: 0.5838401156869993,\n",
    "60: 0.5769313010901846,\n",
    "61: 0.5853905527836535,\n",
    "62: 0.5791834196270187,\n",
    "63: 0.5835596565872005,\n",
    "64: 0.5768400745365255,\n",
    "65: 0.58730998199216,\n",
    "66: 0.5857468618086068,\n",
    "67: 0.5829132727432849,\n",
    "68: 0.5866892776653401,\n",
    "69: 0.5835736542390321,\n",
    "70: 0.5908803740991234,\n",
    "71: 0.5860753838269609,\n",
    "72: 0.591718548379649,\n",
    "73: 0.5855402892120884,\n",
    "74: 0.5870646887876746,\n",
    "75: 0.5890894362540918,\n",
    "76: 0.5850219146482122,\n",
    "77: 0.5976802417411554,\n",
    "78: 0.5966066235999791,\n",
    "79: 0.5909052526418951,\n",
    "80: 0.5914149690791691,\n",
    "81: 0.588638107450284,\n",
    "82: 0.5982624647890482,\n",
    "83: 0.5919376360149863,\n",
    "84: 0.591690670772064,\n",
    "85: 0.5956608126535191,\n",
    "86: 0.5900205384602405,\n",
    "87: 0.5849451849895879,\n",
    "88: 0.5977629622172641,\n",
    "89: 0.5951743906027032,\n",
    "90: 0.589339686740251,\n",
    "91: 0.5930468645841316,\n",
    "92: 0.5956691589027172,\n",
    "93: 0.6025397308736322,\n",
    "94: 0.5889068945594607,\n",
    "95: 0.5880146585017813,\n",
    "96: 0.5934284646692032,\n",
    "97: 0.5922325497630925,\n",
    "98: 0.5940208319390627,\n",
    "99: 0.5928618271066258,\n",
    "100: 0.5997715470418019,\n",
    "101: 0.5936044483227778,\n",
    "102: 0.6019279708302815,\n",
    "103: 0.602533213347501,\n",
    "104: 0.5963334880888964,\n",
    "105: 0.6056443506081165,\n",
    "106: 0.5975240593411423,\n",
    "107: 0.5996407021131478,\n",
    "108: 0.5980720428506074,\n",
    "109: 0.5997174959008147,\n",
    "110: 0.5957889875303568,\n",
    "111: 0.5897419788378259,\n",
    "112: 0.604954945505324,\n",
    "113: 0.5965052851714433,\n",
    "114: 0.5996444288962524,\n",
    "115: 0.5968878253051683,\n",
    "116: 0.5968830911135741,\n",
    "117: 0.5959090809270695,\n",
    "118: 0.5954475162322458,\n",
    "119: 0.5935398169335802,\n",
    "120: 0.6008621203306549,\n",
    "121: 0.5935926291360449,\n",
    "122: 0.598130725778889,\n",
    "123: 0.5992313861028281,\n",
    "124: 0.6046693795739174,\n",
    "125: 0.5982298129263828,\n",
    "126: 0.5960232860668049,\n",
    "127: 0.6044030973583031,\n",
    "128: 0.6016315286809397,\n",
    "129: 0.5993810173063113,\n",
    "130: 0.6035635365737249,\n",
    "131: 0.5960069968790899,\n",
    "132: 0.6056257429150487,\n",
    "133: 0.600188405379896,\n",
    "134: 0.5967969840673589,\n",
    "135: 0.5984067445432787,\n",
    "136: 0.5995909999844236,\n",
    "137: 0.5975813884176463,\n",
    "138: 0.5965913757219914,\n",
    "139: 0.598502158495668,\n",
    "140: 0.601628647696401,\n",
    "141: 0.5990295963140886,\n",
    "142: 0.6018796142334553,\n",
    "143: 0.6005148864906379,\n",
    "144: 0.6060244873239914,\n",
    "145: 0.5990622433254885,\n",
    "146: 0.6024550369665722,\n",
    "147: 0.5982357369548141,\n",
    "148: 0.5941325646884903,\n",
    "149: 0.59390069623016,\n",
    "150: 0.6039272528846477,\n",
    "151: 0.6021946692323404,\n",
    "152: 0.5972795271942584,\n",
    "153: 0.5961772388549483,\n",
    "154: 0.5978389785606532,\n",
    "155: 0.5986978796660438,\n",
    "156: 0.5937174213925309,\n",
    "157: 0.5964659126954226,\n",
    "158: 0.5931876382981576,\n",
    "159: 0.5989935011466829,\n",
    "160: 0.6033812717724114,\n",
    "161: 0.5933660409255077,\n",
    "162: 0.5952806490489172,\n",
    "163: 0.6002842780774261,\n",
    "164: 0.5946705025206782,\n",
    "165: 0.5938611334270604,\n",
    "166: 0.5984334586790975,\n",
    "167: 0.5902319805265897,\n",
    "168: 0.5957562225473998,\n",
    "169: 0.5898155905723946,\n",
    "170: 0.5966538427425229,\n",
    "171: 0.5959718450678335,\n",
    "172: 0.5915919146160262,\n",
    "173: 0.5942350283543748,\n",
    "174: 0.5922126637654017,\n",
    "175: 0.5980340959079492,\n",
    "176: 0.5993834971239988,\n",
    "177: 0.5917323956786577,\n",
    "178: 0.5912710229732072,\n",
    "179: 0.5917924658598762,\n",
    "180: 0.5954777918279443,\n",
    "181: 0.5952622380893326,\n",
    "182: 0.5972004793007989,\n",
    "183: 0.5944789366774792,\n",
    "184: 0.5961397893404531,\n",
    "185: 0.5917107267254932,\n",
    "186: 0.5982468042046421,\n",
    "187: 0.5946353029572638,\n",
    "188: 0.5966010173083319,\n",
    "189: 0.5953617845136727,\n",
    "190: 0.5954982432564551,\n",
    "191: 0.5990859396530512,\n",
    "192: 0.5946907544251899,\n",
    "193: 0.5973111028133703,\n",
    "194: 0.5943374175188729,\n",
    "195: 0.5954679820852285,\n",
    "196: 0.5963061032378455,\n",
    "197: 0.5955680267755166,\n",
    "198: 0.5958295477843897,\n",
    "199: 0.5982870428479249,\n",
    "200: 0.5963349634690889,\n",
    "\n",
    "}\n",
    "\n",
    "# Erstellen eines DataFrames\n",
    "df_log_loss = pd.DataFrame(list(log_loss.items()), columns=[\"Index\", \"Log Loss\"])\n",
    "df_gini = pd.DataFrame(list(gini.items()), columns=[\"Index\", \"Gini\"])\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Log Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_log_loss[\"Index\"], df_log_loss[\"Log Loss\"], label=\"Log Loss\", color=\"b\", marker='o')\n",
    "plt.title('Log Loss über Indizes')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Gini plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_gini[\"Index\"], df_gini[\"Gini\"], label=\"Gini\", color=\"r\", marker='x')\n",
    "plt.title('Gini über Indizes')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Gini')\n",
    "plt.grid(True)\n",
    "\n",
    "# Anzeigen des Plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Train mehere Dateien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainAuto:\n",
    "    def __init__(self, path):\n",
    "        self.paths = [os.path.relpath(os.path.join(path, datei)) for datei in os.listdir(path) if os.path.isfile(os.path.join(path, datei))]\n",
    "        self.data = pd.DataFrame(columns=[\"Datei\", \"criterion\", \"max_depth\", \"min_sample_split\", \"f_score\", \"precision\", \"recall\"])\n",
    "    \n",
    "    def __save(self):\n",
    "        self.data.to_csv(\"trainAuto.csv\", index=False, encoding=\"utf-8\")\n",
    "        print(\"\\nData gesichert\")\n",
    "    \n",
    "    def train(self):\n",
    "        gesamt = len(self.paths)\n",
    "        \n",
    "        for i, path in enumerate(self.paths, start=1):\n",
    "            prozent = (i / gesamt) * 100\n",
    "            länge = 50\n",
    "            balken_länge = int(länge * i // gesamt)\n",
    "            balken = f\"[{'#' * balken_länge}{'.' * (länge - balken_länge)}]\"\n",
    "            sys.stdout.write(f\"\\r{balken} {prozent:.2f}% ({i}/{gesamt})\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            tree = trainMan(path=path, criterionVal=\"entropy\")\n",
    "            max_depth = tree.max_depth(50, 150)\n",
    "            f_score, precision, recall = tree.out()\n",
    "            \n",
    "            self.data = pd.concat([self.data, pd.DataFrame({\n",
    "                \"Datei\": [path], \n",
    "                \"criterion\": [\"entropy\"], \n",
    "                \"max_depth\": [max_depth], \n",
    "                \"min_sample_split\": [2], \n",
    "                \"f_score\": [f_score], \n",
    "                \"precision\": [precision], \n",
    "                \"recall\": [recall]\n",
    "            })])\n",
    "        \n",
    "        self.__save()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####..............................................] 8.33% (2/24)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jona Lissner\\AppData\\Local\\Temp\\ipykernel_8524\\310901499.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.data = pd.concat([self.data, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##################################################] 100.00% (24/24)\n",
      "Data gesichert\n"
     ]
    }
   ],
   "source": [
    "test = trainAuto(\"csv/CSV Processed\")\n",
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei               csv\\CSV Processed\\20newsgroups_processed_11000...\n",
      "criterion                                                     entropy\n",
      "max_depth                                                          85\n",
      "min_sample_split                                                    2\n",
      "f_score                                                      0.630281\n",
      "precision                                                     0.62857\n",
      "recall                                                       0.657234\n",
      "Name: 2, dtype: object\n",
      "Datei               csv\\CSV Processed\\20newsgroups_processed_11000...\n",
      "criterion                                                     entropy\n",
      "max_depth                                                          85\n",
      "min_sample_split                                                    2\n",
      "f_score                                                      0.630281\n",
      "precision                                                     0.62857\n",
      "recall                                                       0.657234\n",
      "Name: 2, dtype: object\n",
      "Datei               csv\\CSV Processed\\20newsgroups_processed_8000.csv\n",
      "criterion                                                     entropy\n",
      "max_depth                                                          81\n",
      "min_sample_split                                                    2\n",
      "f_score                                                      0.627078\n",
      "precision                                                    0.622599\n",
      "recall                                                       0.661546\n",
      "Name: 22, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"trainAuto.csv\")\n",
    "print(data.iloc[data[\"f_score\"].idxmax()])\n",
    "print(data.iloc[data[\"precision\"].idxmax()])\n",
    "print(data.iloc[data[\"recall\"].idxmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiumKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
