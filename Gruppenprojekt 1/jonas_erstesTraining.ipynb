{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd \n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>=</th>\n",
       "      <th></th>\n",
       "      <th>&gt;</th>\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th></th>\n",
       "      <th>don\\'t</th>\n",
       "      <th>people</th>\n",
       "      <th>like</th>\n",
       "      <th>...</th>\n",
       "      <th>media</th>\n",
       "      <th>charge</th>\n",
       "      <th>washington</th>\n",
       "      <th>let\\</th>\n",
       "      <th>moment</th>\n",
       "      <th>published</th>\n",
       "      <th>fairly</th>\n",
       "      <th>refer</th>\n",
       "      <th>child</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "      <td>3370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361128</td>\n",
       "      <td>0.359644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>1.427003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.644304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.288982</td>\n",
       "      <td>1.019855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198471</td>\n",
       "      <td>0.177970</td>\n",
       "      <td>0.368187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208677</td>\n",
       "      <td>0.184521</td>\n",
       "      <td>0.150893</td>\n",
       "      <td>0.254789</td>\n",
       "      <td>0.254789</td>\n",
       "      <td>1.043509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    =               >                space               \\\n",
       "count  3370.0  3370.0  3370.0  3370.0  3370.0  3370.000000       3370.0   \n",
       "mean      0.0     0.0     0.0     0.0     0.0     0.400593          0.0   \n",
       "std       0.0     0.0     0.0     0.0     0.0     2.644304          0.0   \n",
       "min       0.0     0.0     0.0     0.0     0.0     0.000000          0.0   \n",
       "25%       0.0     0.0     0.0     0.0     0.0     0.000000          0.0   \n",
       "50%       0.0     0.0     0.0     0.0     0.0     0.000000          0.0   \n",
       "75%       0.0     0.0     0.0     0.0     0.0     0.000000          0.0   \n",
       "max       0.0     0.0     0.0     0.0     0.0    70.000000          0.0   \n",
       "\n",
       "       don\\'t       people         like  ...        media       charge  \\\n",
       "count  3370.0  3370.000000  3370.000000  ...  3370.000000  3370.000000   \n",
       "mean      0.0     0.361128     0.359644  ...     0.019585     0.019585   \n",
       "std       0.0     1.288982     1.019855  ...     0.198471     0.177970   \n",
       "min       0.0     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "25%       0.0     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "50%       0.0     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "75%       0.0     0.000000     0.000000  ...     0.000000     0.000000   \n",
       "max       0.0    28.000000    20.000000  ...     6.000000     4.000000   \n",
       "\n",
       "        washington    let\\       moment    published       fairly  \\\n",
       "count  3370.000000  3370.0  3370.000000  3370.000000  3370.000000   \n",
       "mean      0.019585     0.0     0.019585     0.019585     0.019585   \n",
       "std       0.368187     0.0     0.208677     0.184521     0.150893   \n",
       "min       0.000000     0.0     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.0     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.0     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.0     0.000000     0.000000     0.000000   \n",
       "max      19.000000     0.0     8.000000     4.000000     2.000000   \n",
       "\n",
       "             refer        child      groupID  \n",
       "count  3370.000000  3370.000000  3370.000000  \n",
       "mean      0.019585     0.019585     1.427003  \n",
       "std       0.254789     0.254789     1.043509  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     1.000000  \n",
       "50%       0.000000     0.000000     1.000000  \n",
       "75%       0.000000     0.000000     2.000000  \n",
       "max      12.000000     7.000000     3.000000  \n",
       "\n",
       "[8 rows x 1001 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"20newsgroups_processed.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:1000]\n",
    "\n",
    "y = data[[\"groupID\"]].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3370, 1001)\n",
      "(3370, 1000)\n",
      "(3370,)\n",
      "(2696, 1000)\n",
      "(2696,)\n",
      "(674, 1000)\n",
      "(674,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.6147019863597404\n",
      "Precision:  0.6869533599837496\n",
      "Recall:  0.642433234421365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average='macro'))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='weighted'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code zum Teste welche max_depth die beste bis 200 ist --> 200 ist Erfahrung, nichts wird dann mehr besser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0.23336718067395565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.00      0.00      0.00       159\n",
      "    Graphics       0.31      0.98      0.47       193\n",
      "       Space       0.90      0.31      0.46       197\n",
      "    Religion       0.00      0.00      0.00       125\n",
      "\n",
      "    accuracy                           0.37       674\n",
      "   macro avg       0.30      0.32      0.23       674\n",
      "weighted avg       0.35      0.37      0.27       674\n",
      "\n",
      "2:0.3059842416150827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.53      0.17      0.26       159\n",
      "    Graphics       0.34      0.98      0.50       193\n",
      "       Space       0.91      0.31      0.46       197\n",
      "    Religion       0.00      0.00      0.00       125\n",
      "\n",
      "    accuracy                           0.41       674\n",
      "   macro avg       0.44      0.36      0.31       674\n",
      "weighted avg       0.49      0.41      0.34       674\n",
      "\n",
      "3:0.32464710961005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       1.00      0.04      0.07       159\n",
      "    Graphics       0.34      0.98      0.50       193\n",
      "       Space       0.92      0.31      0.46       197\n",
      "    Religion       0.48      0.18      0.26       125\n",
      "\n",
      "    accuracy                           0.41       674\n",
      "   macro avg       0.69      0.38      0.32       674\n",
      "weighted avg       0.69      0.41      0.34       674\n",
      "\n",
      "4:0.33833714659574904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.15      0.24       159\n",
      "    Graphics       0.88      0.38      0.53       193\n",
      "       Space       0.36      0.97      0.52       197\n",
      "    Religion       0.50      0.03      0.06       125\n",
      "\n",
      "    accuracy                           0.44       674\n",
      "   macro avg       0.57      0.39      0.34       674\n",
      "weighted avg       0.58      0.44      0.37       674\n",
      "\n",
      "5:0.3609512410197733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.16      0.25       159\n",
      "    Graphics       0.87      0.47      0.61       193\n",
      "       Space       0.37      0.97      0.54       197\n",
      "    Religion       0.43      0.02      0.05       125\n",
      "\n",
      "    accuracy                           0.46       674\n",
      "   macro avg       0.56      0.41      0.36       674\n",
      "weighted avg       0.57      0.46      0.40       674\n",
      "\n",
      "6:0.41521658084143936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.30      0.93      0.46       159\n",
      "    Graphics       0.86      0.47      0.61       193\n",
      "       Space       0.93      0.35      0.50       197\n",
      "    Religion       0.67      0.05      0.09       125\n",
      "\n",
      "    accuracy                           0.46       674\n",
      "   macro avg       0.69      0.45      0.42       674\n",
      "weighted avg       0.71      0.46      0.45       674\n",
      "\n",
      "8:0.4194880270679489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.64      0.26      0.37       159\n",
      "    Graphics       0.87      0.52      0.65       193\n",
      "       Space       0.39      0.96      0.56       197\n",
      "    Religion       0.70      0.06      0.10       125\n",
      "\n",
      "    accuracy                           0.50       674\n",
      "   macro avg       0.65      0.45      0.42       674\n",
      "weighted avg       0.64      0.50      0.45       674\n",
      "\n",
      "10:0.4304778443722037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.25      0.35       159\n",
      "    Graphics       0.85      0.54      0.66       193\n",
      "       Space       0.40      0.95      0.57       197\n",
      "    Religion       0.50      0.09      0.15       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.59      0.46      0.43       674\n",
      "weighted avg       0.59      0.51      0.46       674\n",
      "\n",
      "11:0.4341082354777053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.63      0.25      0.35       159\n",
      "    Graphics       0.86      0.55      0.67       193\n",
      "       Space       0.40      0.95      0.56       197\n",
      "    Religion       0.46      0.09      0.15       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.59      0.46      0.43       674\n",
      "weighted avg       0.60      0.51      0.47       674\n",
      "\n",
      "12:0.44074935691211115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.23      0.33       159\n",
      "    Graphics       0.85      0.54      0.66       193\n",
      "       Space       0.41      0.93      0.57       197\n",
      "    Religion       0.40      0.13      0.19       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.57      0.46      0.44       674\n",
      "weighted avg       0.58      0.51      0.47       674\n",
      "\n",
      "13:0.4756235018629463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.25      0.35       159\n",
      "    Graphics       0.86      0.55      0.68       193\n",
      "       Space       0.42      0.93      0.58       197\n",
      "    Religion       0.50      0.21      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.60      0.49      0.48       674\n",
      "weighted avg       0.61      0.53      0.50       674\n",
      "\n",
      "14:0.4780887670379157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.25      0.35       159\n",
      "    Graphics       0.84      0.56      0.67       193\n",
      "       Space       0.43      0.92      0.58       197\n",
      "    Religion       0.53      0.22      0.31       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.60      0.49      0.48       674\n",
      "weighted avg       0.60      0.53      0.50       674\n",
      "\n",
      "15:0.48237946934808223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.26      0.37       159\n",
      "    Graphics       0.85      0.58      0.69       193\n",
      "       Space       0.42      0.92      0.58       197\n",
      "    Religion       0.53      0.20      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.61      0.49      0.48       674\n",
      "weighted avg       0.61      0.53      0.51       674\n",
      "\n",
      "17:0.48971234292358023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.28      0.38       159\n",
      "    Graphics       0.85      0.56      0.68       193\n",
      "       Space       0.43      0.93      0.59       197\n",
      "    Religion       0.55      0.22      0.31       125\n",
      "\n",
      "    accuracy                           0.54       674\n",
      "   macro avg       0.61      0.50      0.49       674\n",
      "weighted avg       0.62      0.54      0.51       674\n",
      "\n",
      "18:0.5154415766838367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.34      0.85      0.48       159\n",
      "    Graphics       0.85      0.57      0.68       193\n",
      "       Space       0.91      0.46      0.61       197\n",
      "    Religion       0.56      0.19      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.66      0.52      0.52       674\n",
      "weighted avg       0.69      0.53      0.54       674\n",
      "\n",
      "20:0.5426763555186807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.33      0.79      0.47       159\n",
      "    Graphics       0.84      0.59      0.69       193\n",
      "       Space       0.93      0.47      0.62       197\n",
      "    Religion       0.58      0.30      0.39       125\n",
      "\n",
      "    accuracy                           0.54       674\n",
      "   macro avg       0.67      0.53      0.54       674\n",
      "weighted avg       0.70      0.54      0.56       674\n",
      "\n",
      "23:0.5427497653179365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.37      0.46       159\n",
      "    Graphics       0.86      0.61      0.71       193\n",
      "       Space       0.47      0.89      0.61       197\n",
      "    Religion       0.56      0.29      0.38       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.63      0.54      0.54       674\n",
      "weighted avg       0.63      0.58      0.56       674\n",
      "\n",
      "25:0.5463225922887875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.40      0.48       159\n",
      "    Graphics       0.85      0.62      0.72       193\n",
      "       Space       0.48      0.88      0.62       197\n",
      "    Religion       0.56      0.27      0.37       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.62      0.54      0.55       674\n",
      "weighted avg       0.63      0.58      0.57       674\n",
      "\n",
      "26:0.5477942690275176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.40      0.48       159\n",
      "    Graphics       0.84      0.61      0.71       193\n",
      "       Space       0.48      0.90      0.62       197\n",
      "    Religion       0.59      0.28      0.38       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.63      0.55      0.55       674\n",
      "weighted avg       0.63      0.58      0.57       674\n",
      "\n",
      "27:0.5610504411099342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.40      0.48       159\n",
      "    Graphics       0.85      0.62      0.72       193\n",
      "       Space       0.49      0.90      0.63       197\n",
      "    Religion       0.61      0.31      0.41       125\n",
      "\n",
      "    accuracy                           0.59       674\n",
      "   macro avg       0.64      0.56      0.56       674\n",
      "weighted avg       0.64      0.59      0.58       674\n",
      "\n",
      "28:0.5733614693886971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.63      0.40      0.49       159\n",
      "    Graphics       0.85      0.63      0.72       193\n",
      "       Space       0.49      0.87      0.63       197\n",
      "    Religion       0.60      0.37      0.46       125\n",
      "\n",
      "    accuracy                           0.60       674\n",
      "   macro avg       0.64      0.57      0.57       674\n",
      "weighted avg       0.64      0.60      0.59       674\n",
      "\n",
      "35:0.5847935580303225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.43      0.51       159\n",
      "    Graphics       0.83      0.68      0.75       193\n",
      "       Space       0.52      0.86      0.64       197\n",
      "    Religion       0.58      0.36      0.44       125\n",
      "\n",
      "    accuracy                           0.61       674\n",
      "   macro avg       0.63      0.58      0.58       674\n",
      "weighted avg       0.64      0.61      0.60       674\n",
      "\n",
      "44:0.5863667860646924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.43      0.50       159\n",
      "    Graphics       0.86      0.74      0.79       193\n",
      "       Space       0.53      0.89      0.66       197\n",
      "    Religion       0.58      0.29      0.39       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.64      0.59      0.59       674\n",
      "weighted avg       0.65      0.63      0.61       674\n",
      "\n",
      "46:0.5876104379400323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.39      0.47       159\n",
      "    Graphics       0.84      0.72      0.78       193\n",
      "       Space       0.53      0.87      0.66       197\n",
      "    Religion       0.57      0.37      0.45       125\n",
      "\n",
      "    accuracy                           0.62       674\n",
      "   macro avg       0.63      0.59      0.59       674\n",
      "weighted avg       0.64      0.62      0.61       674\n",
      "\n",
      "54:0.5944085347317221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.42      0.49       159\n",
      "    Graphics       0.86      0.74      0.79       193\n",
      "       Space       0.54      0.88      0.67       197\n",
      "    Religion       0.56      0.34      0.42       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.64      0.59      0.59       674\n",
      "weighted avg       0.65      0.63      0.62       674\n",
      "\n",
      "65:0.5951784347251003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.43      0.50       159\n",
      "    Graphics       0.81      0.77      0.79       193\n",
      "       Space       0.56      0.84      0.67       197\n",
      "    Religion       0.55      0.34      0.42       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.63      0.60      0.60       674\n",
      "weighted avg       0.64      0.63      0.62       674\n",
      "\n",
      "69:0.606299126743449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.47      0.53       159\n",
      "    Graphics       0.80      0.75      0.77       193\n",
      "       Space       0.57      0.85      0.68       197\n",
      "    Religion       0.58      0.35      0.44       125\n",
      "\n",
      "    accuracy                           0.64       674\n",
      "   macro avg       0.64      0.61      0.61       674\n",
      "weighted avg       0.65      0.64      0.63       674\n",
      "\n",
      "80:0.6147019863597404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.52      0.55       159\n",
      "    Graphics       0.83      0.74      0.78       193\n",
      "       Space       0.57      0.83      0.67       197\n",
      "    Religion       0.58      0.37      0.45       125\n",
      "\n",
      "    accuracy                           0.64       674\n",
      "   macro avg       0.64      0.61      0.61       674\n",
      "weighted avg       0.65      0.64      0.63       674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "i_mem = 0\n",
    "for i in range(200):\n",
    "    if(i==0):\n",
    "        continue\n",
    "    clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=i)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predict = clf.predict(X_test)\n",
    "    if f1_score(predict, y_test, average='macro')>f:\n",
    "        f = f1_score(predict, y_test, average='macro')\n",
    "        i_mem = i\n",
    "        print(str(i_mem)+\":\"+str(f))\n",
    "        report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "        print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cdoe zum Testen welche Gewichtung der Klassen die Beste ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.6250351364321953\n",
      "Precision:  0.6253301288811098\n",
      "Recall:  0.6500917090775308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.49      0.55       159\n",
      "    Graphics       0.81      0.76      0.79       193\n",
      "       Space       0.61      0.87      0.72       197\n",
      "    Religion       0.57      0.38      0.45       125\n",
      "\n",
      "    accuracy                           0.66       674\n",
      "   macro avg       0.65      0.63      0.63       674\n",
      "weighted avg       0.66      0.66      0.65       674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0: 'atheism' 1: 'graphics' 2: 'space' 3: 'religion.misc'\n",
    "class_weights = {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n",
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80, class_weight=class_weights)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average=\"macro\"))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='macro'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='macro'))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}:0.6147019863597404\n",
      "{0: 1.0, 1: 3.0, 2: 4.0, 3: 1.0}:0.6246210009246238\n",
      "{0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}:0.6250351364321953\n",
      "Bester F1-Score: 0.6250351364321953\n",
      "Beste class_weights: {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# MÃ¶gliche Gewichtswerte zwischen 1.0 und 5.0 in 0.5-Schritten\n",
    "weight_values = np.arange(1.0, 5.1, 1)\n",
    "\n",
    "# Generiere alle Kombinationen der Gewichtswerte fÃ¼r vier Klassen\n",
    "all_combinations = list(itertools.product(weight_values, repeat=4))\n",
    "\n",
    "# Initialisiere die Variablen zur Speicherung des besten Scores und der besten Gewichte\n",
    "best_f1_score = 0.0\n",
    "best_class_weights = None\n",
    "\n",
    "for weights in all_combinations:\n",
    "    # Definiere ein Dictionary fÃ¼r die Gewichtung jeder Klasse\n",
    "    class_weights = {0: weights[0], 1: weights[1], 2: weights[2], 3: weights[3]}\n",
    "    \n",
    "    # Initialisiere und trainiere den Entscheidungsbaum mit den definierten class_weights\n",
    "    clf = DecisionTreeClassifier(class_weight=class_weights, random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Mache Vorhersagen und berechne die Metriken\n",
    "    predictions = clf.predict(X_test)\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # PrÃ¼fe, ob der aktuelle F1-Score besser ist als der bisher beste\n",
    "    current_f1_score = report['macro avg']['f1-score']\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_class_weights = class_weights\n",
    "        print(str(best_class_weights)+\":\"+str(best_f1_score))\n",
    "\n",
    "# Ausgabe der besten Gewichtung und des besten F1-Scores\n",
    "print(\"Bester F1-Score:\", best_f1_score)\n",
    "print(\"Beste class_weights:\", best_class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiumKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
