{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen von der CSV und aufspalten auf alle 4 Kategorien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"20 newsgroups/20newsgroups.csv\", on_bad_lines='skip', sep=';')\n",
    "data.dropna()\n",
    "data = data.iloc[:,1:3]\n",
    "\n",
    "dataSplit = data.drop(data[data[\"group\"] == 1 ].index)\n",
    "dataSplit = dataSplit.drop(data[data[\"group\"] == 2 ].index)\n",
    "dataAth = data.drop(data[data[\"group\"] != 0 ].index)\n",
    "dataReli = data.drop(data[data[\"group\"] != 3 ].index)\n",
    "\n",
    "dataSpace = data.drop(data[data[\"group\"] != 2 ].index)\n",
    "dataGraphics = data.drop(data[data[\"group\"] != 1 ].index)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufskallieren der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenAth = len(dataAth)\n",
    "lenReli = len(dataReli)\n",
    "lenSpace = len(dataSpace)\n",
    "lenGraphics = len(dataGraphics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983 983 983 983\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(dataAth), len(dataReli), len(dataSpace), len(dataGraphics))\n",
    "def expand(data, length):\n",
    "    repeats = length // len(data)  # Anzahl der kompletten Wiederholungen\n",
    "    remainder = length % len(data) # Anzahl der zusätzlichen Zeilen\n",
    "    # Erstelle den erweiterten Datensatz\n",
    "    expanded_data = pd.concat([data] * repeats + [data.iloc[:remainder]], ignore_index=True)\n",
    "    return expanded_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Skaliere die Datensätze auf die maximale Länge\n",
    "dataAth = expand(dataAth, max_length)\n",
    "dataReli = expand(dataReli, max_length)\n",
    "dataSpace = expand(dataSpace, max_length)\n",
    "dataGraphics = expand(dataGraphics, max_length)\n",
    "\n",
    "# Nun haben alle Datensätze die gleiche Anzahl an Zeilen (max_length)\n",
    "print(len(dataAth), len(dataReli), len(dataSpace), len(dataGraphics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Freq_words Generierung                                                                        \n",
    "Änderung zu vorherigem Code: \n",
    "- toke.text.strip entfernt leere oder Whitespace-only Einträge\n",
    "- regex entfernt alle nicht Zahlen oder Buchstaben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqAth = Counter()\n",
    "for text in dataAth[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqAth.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqReli = Counter()\n",
    "for text in dataReli[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqReli.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqSpace = Counter()\n",
    "for text in dataSpace[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqSpace.update(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqGraphics = Counter()\n",
    "for text in dataGraphics[\"text\"]:\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    filtered_words = [token.text.lower() for token in doc if (not token.is_stop and not token.is_punct and token.text.strip())]\n",
    "    word_freqGraphics.update(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nt', 1095), ('god', 864)]\n",
      "1095\n"
     ]
    }
   ],
   "source": [
    "print(word_freqReli.most_common(2))\n",
    "print(word_freqReli.get(\"nt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generierung der neuen most_common_words:\n",
    "Notwendig sind für 500 Worte:\n",
    "- Reli: \n",
    "- Ath: \n",
    "- Graphics:\n",
    "- Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "faktor = 1\n",
    "faktorRA = 3\n",
    "words = 700\n",
    "\n",
    "freqList_Reli = []\n",
    "for word, freq in word_freqReli.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Reli) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktorRA * freqAth) and \n",
    "        (freqSpace is None or freq >= faktorRA * freqSpace) and \n",
    "        (freqGraphics is None or freq >= faktorRA * freqGraphics)):\n",
    "        freqList_Reli.append(word)\n",
    "\n",
    "\n",
    "freqList_Ath = []\n",
    "for word, freq in word_freqAth.most_common(10000):\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Ath) >= words:\n",
    "        break\n",
    "    if ((freqReli is None or freq >=faktorRA * freqReli) and \n",
    "        (freqSpace is None or freq >= faktorRA * freqSpace) and \n",
    "        (freqGraphics is None or freq >= faktorRA * freqGraphics)):\n",
    "        freqList_Ath.append(word)\n",
    "\n",
    "freqList_Space = []\n",
    "for word, freq in word_freqSpace.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqGraphics = word_freqGraphics.get(word)\n",
    "    if len(freqList_Space) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktor * freqAth) and \n",
    "        (freqGraphics is None or freq >= faktor * freqGraphics) and \n",
    "        (freqReli is None or freq >= faktor * freqReli)):\n",
    "        freqList_Space.append(word)\n",
    "\n",
    "freqList_Graphics = []\n",
    "for word, freq in word_freqGraphics.most_common(10000):\n",
    "    freqAth = word_freqAth.get(word)\n",
    "    freqReli = word_freqReli.get(word)\n",
    "    freqSpace = word_freqSpace.get(word)\n",
    "    if len(freqList_Graphics) >= words:\n",
    "        break\n",
    "    if ((freqAth is None or freq >= faktor * freqAth) and \n",
    "        (freqSpace is None or freq >= faktor * freqSpace) and \n",
    "        (freqReli is None or freq >= faktor * freqReli)):\n",
    "        freqList_Graphics.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datei anlegen und befüllen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument</th>\n",
       "      <th>atheists</th>\n",
       "      <th>atheism</th>\n",
       "      <th>atheist</th>\n",
       "      <th>islam</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>quran</th>\n",
       "      <th>theism</th>\n",
       "      <th>islamic</th>\n",
       "      <th>war</th>\n",
       "      <th>...</th>\n",
       "      <th>axis</th>\n",
       "      <th>electronics</th>\n",
       "      <th>russia</th>\n",
       "      <th>meters</th>\n",
       "      <th>projected</th>\n",
       "      <th>archivename</th>\n",
       "      <th>telescopes</th>\n",
       "      <th>meteor</th>\n",
       "      <th>contest</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [argument, atheists, atheism, atheist, islam, fallacy, quran, theism, islamic, war, statements, altatheism, theists, event, muslim, bobby, valid, premises, deletion, rushdie, social, morals, stay, argumentum, sea, logical, assertion, rational, weak, assumption, liar, blew, gd, beauchaine, bobbeviceicotekcom, irrational, queens, bronx, sank, manhattan, behaviour, occurs, reliable, james, hussein, proposition, imply, logically, br, aa, viewpoint, pink, posters, motto, motivated, disease, fish, deletions, razor, dogma, fanatism, incorrect, cruel, isaiah, psalm, liberty, nonexistence, challenges, invalid, maddi, iraqi, khomeini, stalin, supernatural, penalty, rh, lunatic, arrogant, mom, mozumder, fatwa, brains, mathew, genetic, fallacies, omnipotent, criminal, philosophical, wars, absurd, possibilities, benefactor, kuwait, omniscient, capital, bcci, survival, selim, implication, propositions, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2801 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqList = freqList_Ath+freqList_Reli+freqList_Graphics+freqList_Space+[\"groupID\"]\n",
    "freqListData = pd.DataFrame(columns=freqList)\n",
    "freqListData.to_csv(\"20newsgroups_freqList.csv\", index=False)\n",
    "freqListData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument</th>\n",
       "      <th>atheists</th>\n",
       "      <th>atheism</th>\n",
       "      <th>atheist</th>\n",
       "      <th>islam</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>quran</th>\n",
       "      <th>theism</th>\n",
       "      <th>islamic</th>\n",
       "      <th>war</th>\n",
       "      <th>...</th>\n",
       "      <th>axis</th>\n",
       "      <th>electronics</th>\n",
       "      <th>russia</th>\n",
       "      <th>meters</th>\n",
       "      <th>projected</th>\n",
       "      <th>archivename</th>\n",
       "      <th>telescopes</th>\n",
       "      <th>meteor</th>\n",
       "      <th>contest</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   argument  atheists  atheism  atheist  islam  fallacy  quran  theism  \\\n",
       "0         0         0        0        0      0        0      0       0   \n",
       "1         0         0        0        0      0        0      0       0   \n",
       "2         0         0        0        0      0        0      0       0   \n",
       "3         0         0        0        0      0        0      0       0   \n",
       "4         0         0        0        0      0        0      0       0   \n",
       "\n",
       "   islamic  war  ...  axis  electronics  russia  meters  projected  \\\n",
       "0        0    0  ...     0            0       0       0          0   \n",
       "1        0    0  ...     0            0       0       0          0   \n",
       "2        0    0  ...     0            0       0       0          0   \n",
       "3        0    0  ...     0            0       0       0          0   \n",
       "4        0    0  ...     0            0       0       0          0   \n",
       "\n",
       "   archivename  telescopes  meteor  contest  groupID  \n",
       "0            0           0       0        0        1  \n",
       "1            0           0       0        0        3  \n",
       "2            0           0       0        0        2  \n",
       "3            0           0       0        0        0  \n",
       "4            0           0       0        0        2  \n",
       "\n",
       "[5 rows x 2797 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqListData_list = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    text = str(row['text'])\n",
    "    group = str(row['group'])\n",
    "    doc = nlp(text)\n",
    "    count_in_freqList = Counter(token.text.lower() for token in doc if token.is_alpha)\n",
    "\n",
    "    haeufigkeiten = {word: count_in_freqList.get(word, 0) for word in freqList}\n",
    "    haeufigkeiten['groupID'] = group\n",
    "    \n",
    "    # Füge die Häufigkeiten als Liste der Ergebnisse hinzu\n",
    "    freqListData_list.append(haeufigkeiten)\n",
    "\n",
    "# Übertrage die verschachtelte Liste nach dem Durchlauf in ein DataFrame\n",
    "freqListData = pd.DataFrame(freqListData_list)\n",
    "\n",
    "# Speichere das DataFrame in einer CSV-Datei\n",
    "freqListData.to_csv(\"20newsgroups_freqList.csv\", index=False)\n",
    "\n",
    "# Zeige die ersten paar Zeilen des DataFrames\n",
    "freqListData.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiumKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
