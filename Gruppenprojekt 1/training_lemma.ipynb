{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd \n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3277, 1001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"20newsgroups_processed_lemmatized.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:1000]\n",
    "\n",
    "y = data[[\"groupID\"]].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3277, 1001)\n",
      "(3277, 1000)\n",
      "(3277,)\n",
      "(2621, 1000)\n",
      "(2621,)\n",
      "(656, 1000)\n",
      "(656,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted\n",
      "F-Score:  0.6261836088004885\n",
      "Precision:  0.6436340296417319\n",
      "Recall:  0.6204268292682927\n",
      "\n",
      "macro\n",
      "F-Score:  0.594381834201452\n",
      "Precision:  0.5932011112826053\n",
      "Recall:  0.6087306336784086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print('weighted')\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average='weighted'))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='weighted'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='weighted'))\n",
    "\n",
    "\n",
    "print('\\nmacro')\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average='macro'))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='macro'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code zum Teste welche max_depth die beste bis 200 ist --> 200 ist Erfahrung, nichts wird dann mehr besser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0.22610674693487998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.00      0.00      0.00       155\n",
      "    Graphics       0.30      0.93      0.46       190\n",
      "       Space       0.79      0.31      0.45       190\n",
      "    Religion       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.36       656\n",
      "   macro avg       0.27      0.31      0.23       656\n",
      "weighted avg       0.32      0.36      0.26       656\n",
      "\n",
      "2:0.30439775504591016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dominik/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.46      0.19      0.27       155\n",
      "    Graphics       0.34      0.94      0.50       190\n",
      "       Space       0.81      0.31      0.44       190\n",
      "    Religion       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.41       656\n",
      "   macro avg       0.40      0.36      0.30       656\n",
      "weighted avg       0.44      0.41      0.34       656\n",
      "\n",
      "3:0.34795288050471485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.78      0.05      0.09       155\n",
      "    Graphics       0.34      0.94      0.50       190\n",
      "       Space       0.81      0.31      0.44       190\n",
      "    Religion       0.57      0.26      0.36       121\n",
      "\n",
      "    accuracy                           0.42       656\n",
      "   macro avg       0.62      0.39      0.35       656\n",
      "weighted avg       0.62      0.42      0.36       656\n",
      "\n",
      "4:0.3638195334178004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.83      0.06      0.12       155\n",
      "    Graphics       0.83      0.31      0.45       190\n",
      "       Space       0.36      0.97      0.52       190\n",
      "    Religion       0.58      0.26      0.36       121\n",
      "\n",
      "    accuracy                           0.43       656\n",
      "   macro avg       0.65      0.40      0.36       656\n",
      "weighted avg       0.65      0.43      0.38       656\n",
      "\n",
      "5:0.3791886225267338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.23      0.33       155\n",
      "    Graphics       0.83      0.32      0.46       190\n",
      "       Space       0.37      0.97      0.54       190\n",
      "    Religion       0.64      0.12      0.20       121\n",
      "\n",
      "    accuracy                           0.45       656\n",
      "   macro avg       0.60      0.41      0.38       656\n",
      "weighted avg       0.60      0.45      0.40       656\n",
      "\n",
      "6:0.401236823903214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.56      0.23      0.33       155\n",
      "    Graphics       0.83      0.40      0.54       190\n",
      "       Space       0.38      0.95      0.54       190\n",
      "    Religion       0.61      0.12      0.19       121\n",
      "\n",
      "    accuracy                           0.47       656\n",
      "   macro avg       0.59      0.43      0.40       656\n",
      "weighted avg       0.59      0.47      0.43       656\n",
      "\n",
      "7:0.4100920008429594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.23      0.33       155\n",
      "    Graphics       0.84      0.39      0.54       190\n",
      "       Space       0.38      0.95      0.54       190\n",
      "    Religion       0.63      0.14      0.23       121\n",
      "\n",
      "    accuracy                           0.47       656\n",
      "   macro avg       0.61      0.43      0.41       656\n",
      "weighted avg       0.61      0.47      0.43       656\n",
      "\n",
      "8:0.44960597163195487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.24      0.34       155\n",
      "    Graphics       0.85      0.53      0.65       190\n",
      "       Space       0.40      0.94      0.56       190\n",
      "    Religion       0.67      0.15      0.24       121\n",
      "\n",
      "    accuracy                           0.51       656\n",
      "   macro avg       0.63      0.47      0.45       656\n",
      "weighted avg       0.62      0.51      0.48       656\n",
      "\n",
      "9:0.4604784905486475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.52      0.24      0.33       155\n",
      "    Graphics       0.86      0.53      0.66       190\n",
      "       Space       0.40      0.91      0.55       190\n",
      "    Religion       0.65      0.20      0.30       121\n",
      "\n",
      "    accuracy                           0.51       656\n",
      "   macro avg       0.61      0.47      0.46       656\n",
      "weighted avg       0.61      0.51      0.48       656\n",
      "\n",
      "10:0.4738262966202784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.53      0.24      0.33       155\n",
      "    Graphics       0.86      0.53      0.66       190\n",
      "       Space       0.41      0.91      0.56       190\n",
      "    Religion       0.64      0.24      0.35       121\n",
      "\n",
      "    accuracy                           0.52       656\n",
      "   macro avg       0.61      0.48      0.47       656\n",
      "weighted avg       0.61      0.52      0.49       656\n",
      "\n",
      "11:0.4763475269376135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.54      0.28      0.37       155\n",
      "    Graphics       0.86      0.54      0.66       190\n",
      "       Space       0.41      0.92      0.57       190\n",
      "    Religion       0.71      0.20      0.31       121\n",
      "\n",
      "    accuracy                           0.52       656\n",
      "   macro avg       0.63      0.48      0.48       656\n",
      "weighted avg       0.63      0.52      0.50       656\n",
      "\n",
      "12:0.4971600398081093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.25      0.34       155\n",
      "    Graphics       0.88      0.59      0.70       190\n",
      "       Space       0.42      0.91      0.57       190\n",
      "    Religion       0.66      0.26      0.37       121\n",
      "\n",
      "    accuracy                           0.54       656\n",
      "   macro avg       0.63      0.50      0.50       656\n",
      "weighted avg       0.63      0.54      0.52       656\n",
      "\n",
      "14:0.5183739559239727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.51      0.40      0.45       155\n",
      "    Graphics       0.87      0.59      0.70       190\n",
      "       Space       0.45      0.87      0.59       190\n",
      "    Religion       0.68      0.21      0.33       121\n",
      "\n",
      "    accuracy                           0.56       656\n",
      "   macro avg       0.63      0.52      0.52       656\n",
      "weighted avg       0.63      0.56      0.54       656\n",
      "\n",
      "17:0.5479113338296344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.39      0.46       155\n",
      "    Graphics       0.86      0.58      0.70       190\n",
      "       Space       0.46      0.88      0.61       190\n",
      "    Religion       0.63      0.32      0.43       121\n",
      "\n",
      "    accuracy                           0.57       656\n",
      "   macro avg       0.63      0.54      0.55       656\n",
      "weighted avg       0.64      0.57      0.57       656\n",
      "\n",
      "18:0.5517691045450391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.56      0.39      0.46       155\n",
      "    Graphics       0.86      0.58      0.69       190\n",
      "       Space       0.47      0.87      0.61       190\n",
      "    Religion       0.60      0.36      0.45       121\n",
      "\n",
      "    accuracy                           0.58       656\n",
      "   macro avg       0.62      0.55      0.55       656\n",
      "weighted avg       0.63      0.58      0.57       656\n",
      "\n",
      "19:0.5546590649562677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.42      0.47       155\n",
      "    Graphics       0.85      0.58      0.69       190\n",
      "       Space       0.48      0.87      0.62       190\n",
      "    Religion       0.66      0.32      0.43       121\n",
      "\n",
      "    accuracy                           0.58       656\n",
      "   macro avg       0.63      0.55      0.55       656\n",
      "weighted avg       0.64      0.58      0.57       656\n",
      "\n",
      "20:0.5607472562179238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.42      0.47       155\n",
      "    Graphics       0.89      0.63      0.73       190\n",
      "       Space       0.48      0.87      0.62       190\n",
      "    Religion       0.64      0.31      0.41       121\n",
      "\n",
      "    accuracy                           0.59       656\n",
      "   macro avg       0.64      0.56      0.56       656\n",
      "weighted avg       0.64      0.59      0.58       656\n",
      "\n",
      "22:0.5665237259119111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.39      0.46       155\n",
      "    Graphics       0.87      0.61      0.72       190\n",
      "       Space       0.50      0.87      0.63       190\n",
      "    Religion       0.55      0.39      0.45       121\n",
      "\n",
      "    accuracy                           0.59       656\n",
      "   macro avg       0.62      0.56      0.57       656\n",
      "weighted avg       0.63      0.59      0.58       656\n",
      "\n",
      "23:0.5706731750579529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.41      0.47       155\n",
      "    Graphics       0.88      0.61      0.72       190\n",
      "       Space       0.49      0.86      0.63       190\n",
      "    Religion       0.58      0.39      0.47       121\n",
      "\n",
      "    accuracy                           0.59       656\n",
      "   macro avg       0.63      0.57      0.57       656\n",
      "weighted avg       0.64      0.59      0.59       656\n",
      "\n",
      "24:0.5763424306464766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.41      0.48       155\n",
      "    Graphics       0.88      0.64      0.74       190\n",
      "       Space       0.50      0.86      0.63       190\n",
      "    Religion       0.60      0.37      0.46       121\n",
      "\n",
      "    accuracy                           0.60       656\n",
      "   macro avg       0.64      0.57      0.58       656\n",
      "weighted avg       0.64      0.60      0.59       656\n",
      "\n",
      "25:0.5818137641409988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.40      0.48       155\n",
      "    Graphics       0.90      0.64      0.74       190\n",
      "       Space       0.50      0.86      0.63       190\n",
      "    Religion       0.56      0.41      0.47       121\n",
      "\n",
      "    accuracy                           0.60       656\n",
      "   macro avg       0.64      0.58      0.58       656\n",
      "weighted avg       0.65      0.60      0.60       656\n",
      "\n",
      "29:0.589158252064471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.41      0.49       155\n",
      "    Graphics       0.88      0.65      0.75       190\n",
      "       Space       0.50      0.86      0.63       190\n",
      "    Religion       0.60      0.41      0.49       121\n",
      "\n",
      "    accuracy                           0.61       656\n",
      "   macro avg       0.65      0.58      0.59       656\n",
      "weighted avg       0.65      0.61      0.60       656\n",
      "\n",
      "41:0.6041634272409733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.42      0.50       155\n",
      "    Graphics       0.84      0.70      0.76       190\n",
      "       Space       0.53      0.83      0.64       190\n",
      "    Religion       0.59      0.45      0.51       121\n",
      "\n",
      "    accuracy                           0.62       656\n",
      "   macro avg       0.64      0.60      0.60       656\n",
      "weighted avg       0.65      0.62      0.62       656\n",
      "\n",
      "42:0.6053664218466174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.45      0.51       155\n",
      "    Graphics       0.85      0.71      0.77       190\n",
      "       Space       0.53      0.83      0.65       190\n",
      "    Religion       0.60      0.41      0.49       121\n",
      "\n",
      "    accuracy                           0.63       656\n",
      "   macro avg       0.64      0.60      0.61       656\n",
      "weighted avg       0.65      0.63      0.62       656\n",
      "\n",
      "46:0.6093382282596813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.46      0.52       155\n",
      "    Graphics       0.86      0.71      0.77       190\n",
      "       Space       0.52      0.82      0.63       190\n",
      "    Religion       0.61      0.43      0.50       121\n",
      "\n",
      "    accuracy                           0.63       656\n",
      "   macro avg       0.65      0.60      0.61       656\n",
      "weighted avg       0.66      0.63      0.62       656\n",
      "\n",
      "57:0.6113989913018084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.48      0.53       155\n",
      "    Graphics       0.83      0.71      0.77       190\n",
      "       Space       0.57      0.80      0.66       190\n",
      "    Religion       0.55      0.44      0.49       121\n",
      "\n",
      "    accuracy                           0.63       656\n",
      "   macro avg       0.63      0.61      0.61       656\n",
      "weighted avg       0.64      0.63      0.63       656\n",
      "\n",
      "60:0.6182770693170567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.56      0.52      0.54       155\n",
      "    Graphics       0.82      0.74      0.78       190\n",
      "       Space       0.58      0.77      0.66       190\n",
      "    Religion       0.58      0.43      0.49       121\n",
      "\n",
      "    accuracy                           0.64       656\n",
      "   macro avg       0.64      0.61      0.62       656\n",
      "weighted avg       0.65      0.64      0.64       656\n",
      "\n",
      "62:0.620848142186072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.54      0.56       155\n",
      "    Graphics       0.81      0.74      0.77       190\n",
      "       Space       0.58      0.77      0.66       190\n",
      "    Religion       0.58      0.42      0.49       121\n",
      "\n",
      "    accuracy                           0.64       656\n",
      "   macro avg       0.64      0.62      0.62       656\n",
      "weighted avg       0.65      0.64      0.64       656\n",
      "\n",
      "65:0.628508741910268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.54      0.58       155\n",
      "    Graphics       0.80      0.71      0.75       190\n",
      "       Space       0.58      0.78      0.66       190\n",
      "    Religion       0.59      0.47      0.53       121\n",
      "\n",
      "    accuracy                           0.64       656\n",
      "   macro avg       0.65      0.62      0.63       656\n",
      "weighted avg       0.65      0.64      0.64       656\n",
      "\n",
      "77:0.6295151182812553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.55      0.57       155\n",
      "    Graphics       0.80      0.76      0.78       190\n",
      "       Space       0.61      0.76      0.68       190\n",
      "    Religion       0.60      0.43      0.50       121\n",
      "\n",
      "    accuracy                           0.65       656\n",
      "   macro avg       0.64      0.63      0.63       656\n",
      "weighted avg       0.65      0.65      0.65       656\n",
      "\n",
      "79:0.6352681061323381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.57      0.58       155\n",
      "    Graphics       0.78      0.74      0.76       190\n",
      "       Space       0.61      0.75      0.67       190\n",
      "    Religion       0.62      0.46      0.53       121\n",
      "\n",
      "    accuracy                           0.65       656\n",
      "   macro avg       0.65      0.63      0.64       656\n",
      "weighted avg       0.66      0.65      0.65       656\n",
      "\n",
      "84:0.6372734857607056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.55      0.57       155\n",
      "    Graphics       0.80      0.75      0.77       190\n",
      "       Space       0.61      0.75      0.67       190\n",
      "    Religion       0.61      0.48      0.54       121\n",
      "\n",
      "    accuracy                           0.65       656\n",
      "   macro avg       0.65      0.63      0.64       656\n",
      "weighted avg       0.66      0.65      0.65       656\n",
      "\n",
      "126:0.6528637291804523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.57      0.58      0.58       155\n",
      "    Graphics       0.76      0.76      0.76       190\n",
      "       Space       0.72      0.69      0.71       190\n",
      "    Religion       0.55      0.59      0.57       121\n",
      "\n",
      "    accuracy                           0.66       656\n",
      "   macro avg       0.65      0.65      0.65       656\n",
      "weighted avg       0.67      0.66      0.67       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "i_mem = 0\n",
    "for i in range(200):\n",
    "    if(i==0):\n",
    "        continue\n",
    "    clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=i)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predict = clf.predict(X_test)\n",
    "    if f1_score(predict, y_test, average='macro')>f:\n",
    "        f = f1_score(predict, y_test, average='macro')\n",
    "        i_mem = i\n",
    "        print(str(i_mem)+\":\"+str(f))\n",
    "        report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "        print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cdoe zum Testen welche Gewichtung der Klassen die Beste ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.6250351364321953\n",
      "Precision:  0.6253301288811098\n",
      "Recall:  0.6500917090775308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.49      0.55       159\n",
      "    Graphics       0.81      0.76      0.79       193\n",
      "       Space       0.61      0.87      0.72       197\n",
      "    Religion       0.57      0.38      0.45       125\n",
      "\n",
      "    accuracy                           0.66       674\n",
      "   macro avg       0.65      0.63      0.63       674\n",
      "weighted avg       0.66      0.66      0.65       674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0: 'atheism' 1: 'graphics' 2: 'space' 3: 'religion.misc'\n",
    "class_weights = {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n",
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80, class_weight=class_weights)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average=\"macro\"))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='macro'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='macro'))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}:0.6147019863597404\n",
      "{0: 1.0, 1: 3.0, 2: 4.0, 3: 1.0}:0.6246210009246238\n",
      "{0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}:0.6250351364321953\n",
      "Bester F1-Score: 0.6250351364321953\n",
      "Beste class_weights: {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Mögliche Gewichtswerte zwischen 1.0 und 5.0 in 0.5-Schritten\n",
    "weight_values = np.arange(1.0, 5.1, 1)\n",
    "\n",
    "# Generiere alle Kombinationen der Gewichtswerte für vier Klassen\n",
    "all_combinations = list(itertools.product(weight_values, repeat=4))\n",
    "\n",
    "# Initialisiere die Variablen zur Speicherung des besten Scores und der besten Gewichte\n",
    "best_f1_score = 0.0\n",
    "best_class_weights = None\n",
    "\n",
    "for weights in all_combinations:\n",
    "    # Definiere ein Dictionary für die Gewichtung jeder Klasse\n",
    "    class_weights = {0: weights[0], 1: weights[1], 2: weights[2], 3: weights[3]}\n",
    "    \n",
    "    # Initialisiere und trainiere den Entscheidungsbaum mit den definierten class_weights\n",
    "    clf = DecisionTreeClassifier(class_weight=class_weights, random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Mache Vorhersagen und berechne die Metriken\n",
    "    predictions = clf.predict(X_test)\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # Prüfe, ob der aktuelle F1-Score besser ist als der bisher beste\n",
    "    current_f1_score = report['macro avg']['f1-score']\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_class_weights = class_weights\n",
    "        print(str(best_class_weights)+\":\"+str(best_f1_score))\n",
    "\n",
    "# Ausgabe der besten Gewichtung und des besten F1-Scores\n",
    "print(\"Bester F1-Score:\", best_f1_score)\n",
    "print(\"Beste class_weights:\", best_class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
