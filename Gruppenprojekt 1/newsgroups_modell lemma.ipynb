{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas -> CSV-Datein einlesen;\n",
    "spacy -> Satzzeichen und Stopwörter;\n",
    "collections/Counter -> Häufigkeitsverteilung der Wörter;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen des Datensatzes und Definierung der Stopwörter (muss noch erweiter werden auf alle unnötigen Stopwörter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl doppelter Zeilen: 89\n",
      "Anzahl null Zeilen: text     90\n",
      "group     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"20 newsgroups/20newsgroups.csv\", on_bad_lines='skip', sep=';')\n",
    "data = data.iloc[:,1:3]\n",
    "\n",
    "doppelte_zeilen = data.duplicated().sum()\n",
    "na_zeilen = data.isna().sum()\n",
    "data = data.dropna()\n",
    "data = data.drop_duplicates()\n",
    "print(\"Anzahl doppelter Zeilen:\", doppelte_zeilen)\n",
    "print(\"Anzahl null Zeilen:\", na_zeilen)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellung der Häufigkeitsverteilung, mit gleichzeitiger Entfernung von Satzzeichen/Stopwörtern, und Ausgabe der 20 häufigsten Wörter (Ausführung auch hier nicht notwendig, dauert 2min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 häufigste Wörter:\n",
      "image: 1816\n",
      "know: 1408\n",
      "space: 1361\n",
      "god: 1301\n",
      "think: 1242\n",
      "like: 1233\n",
      "people: 1223\n",
      "file: 1119\n",
      "time: 1090\n",
      "system: 1023\n",
      "say: 966\n",
      "use: 937\n",
      "good: 933\n",
      "program: 906\n",
      "find: 861\n",
      "point: 823\n",
      "thing: 821\n",
      "jpeg: 770\n",
      "way: 768\n",
      "look: 759\n"
     ]
    }
   ],
   "source": [
    "word_freq = Counter()\n",
    "\n",
    "for text in data[\"text\"]:\n",
    "    doc = nlp(text)  # NLP-Pipeline auf den Text anwenden\n",
    "    \n",
    "    # Filter und Lemmatisierung in einem Schritt\n",
    "    filtered_words = [\n",
    "        token.lemma_.lower() \n",
    "        for token in doc \n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "    \n",
    "    # Aktualisiere die Häufigkeitsverteilung\n",
    "    word_freq.update(filtered_words)\n",
    "\n",
    "# Ausgabe der Top 20 Wörter\n",
    "print(\"Top 20 häufigste Wörter:\")\n",
    "for word, count in word_freq.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellung der neuen CSV-Datei mit n most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>know</th>\n",
       "      <th>space</th>\n",
       "      <th>god</th>\n",
       "      <th>think</th>\n",
       "      <th>like</th>\n",
       "      <th>people</th>\n",
       "      <th>file</th>\n",
       "      <th>time</th>\n",
       "      <th>system</th>\n",
       "      <th>...</th>\n",
       "      <th>ability</th>\n",
       "      <th>parallel</th>\n",
       "      <th>technique</th>\n",
       "      <th>bright</th>\n",
       "      <th>modern</th>\n",
       "      <th>commit</th>\n",
       "      <th>galaxy</th>\n",
       "      <th>previous</th>\n",
       "      <th>potential</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image, know, space, god, think, like, people, file, time, system, say, use, good, program, find, point, thing, jpeg, way, look, believe, work, want, read, need, format, year, bit, include, available, come, new, try, post, mean, write, jesus, support, datum, book, right, question, software, launch, information, color, go, problem, graphic, version, base, get, send, etc, tell, well, day, line, earth, life, true, religion, high, word, give, mail, bible, world, claim, example, long, different, follow, source, number, display, set, exist, group, help, ftp, run, belief, gif, computer, orbit, mission, fact, take, note, change, satellite, list, see, case, place, free, call, atheist, nasa, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list_length = 1000\n",
    "wort_namen_list = [wort for wort, _ in word_freq.most_common(name_list_length)]\n",
    "wort_namen_list.append('groupID')\n",
    "processedData = pd.DataFrame(columns=wort_namen_list)\n",
    "processedData.to_csv(\"20newsgroups_processed_lemmatized.csv\", index=False)\n",
    "processedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gesamte CSV-Datei (dauert fast 3min --> CSV-Datei ist schon erstellt, ausführen nicht notwendig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image  know  space  god  think  like  people  file  time  system  ...  \\\n",
      "0      0     1      0    0      0     1       0     6     0       0  ...   \n",
      "1      0     0      0    0      1     1       0     0     0       0  ...   \n",
      "2      0     0      0    0      0     0       0     0     0       0  ...   \n",
      "3      0     0      0    0      1     2       0     0     0       0  ...   \n",
      "4      0     1      0    0      0     0       0     0     0       0  ...   \n",
      "\n",
      "   ability  parallel  technique  bright  modern  commit  galaxy  previous  \\\n",
      "0        0         0          0       0       0       0       0         0   \n",
      "1        0         0          0       0       0       0       0         0   \n",
      "2        0         0          0       0       0       0       0         0   \n",
      "3        0         0          0       0       0       0       0         0   \n",
      "4        0         0          0       0       0       0       0         0   \n",
      "\n",
      "   potential  groupID  \n",
      "0          0        1  \n",
      "1          0        3  \n",
      "2          0        2  \n",
      "3          0        0  \n",
      "4          0        2  \n",
      "\n",
      "[5 rows x 1001 columns]\n"
     ]
    }
   ],
   "source": [
    "# Liste zum Speichern der Ergebnisse\n",
    "rows = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    text = str(row['text'])\n",
    "    group = str(row['group'])\n",
    "\n",
    "    doc = nlp(text)\n",
    "    count_in_top_n = Counter(\n",
    "        token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop and not token.is_punct\n",
    "    )\n",
    "\n",
    "    haeufigkeiten = {word: count_in_top_n.get(word, 0) for word in wort_namen_list}\n",
    "    haeufigkeiten['groupID'] = group\n",
    "    rows.append(haeufigkeiten)\n",
    "\n",
    "# Erstelle einen DataFrame aus der Liste der Ergebnisse\n",
    "processedData = pd.DataFrame(rows)\n",
    "\n",
    "# Speichere den DataFrame und gib die ersten Zeilen aus\n",
    "processedData.to_csv(\"20newsgroups_processed_lemmatized.csv\", index=False)\n",
    "print(processedData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einfache Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>=</th>\n",
       "      <th></th>\n",
       "      <th>&gt;</th>\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th></th>\n",
       "      <th>don\\'t</th>\n",
       "      <th>people</th>\n",
       "      <th>like</th>\n",
       "      <th>...</th>\n",
       "      <th>media</th>\n",
       "      <th>charge</th>\n",
       "      <th>washington</th>\n",
       "      <th>let\\</th>\n",
       "      <th>moment</th>\n",
       "      <th>published</th>\n",
       "      <th>fairly</th>\n",
       "      <th>refer</th>\n",
       "      <th>child</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      =       >       space             don\\'t people like  ... media charge  \\\n",
       "0  0  0    0  0     0     0           0      0      0    1  ...     0      0   \n",
       "1  0  0    0  0     0     0           0      0      0    1  ...     0      0   \n",
       "2  0  0    0  0     0     0           0      0      0    0  ...     0      0   \n",
       "3  0  0    0  0     0     0           0      0      0    2  ...     0      0   \n",
       "4  0  0    0  0     0     0           0      0      0    0  ...     0      0   \n",
       "\n",
       "  washington let\\ moment published fairly refer child groupID  \n",
       "0          0    0      0         0      0     0     0       1  \n",
       "1          0    0      0         0      0     0     0       3  \n",
       "2          0    0      0         0      0     0     0       2  \n",
       "3          0    0      0         0      0     0     0       0  \n",
       "4          0    0      0         0      0     0     0       2  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
