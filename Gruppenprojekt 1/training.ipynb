{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd \n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>know</th>\n",
       "      <th>space</th>\n",
       "      <th>god</th>\n",
       "      <th>think</th>\n",
       "      <th>like</th>\n",
       "      <th>people</th>\n",
       "      <th>file</th>\n",
       "      <th>time</th>\n",
       "      <th>system</th>\n",
       "      <th>...</th>\n",
       "      <th>ability</th>\n",
       "      <th>parallel</th>\n",
       "      <th>technique</th>\n",
       "      <th>bright</th>\n",
       "      <th>modern</th>\n",
       "      <th>commit</th>\n",
       "      <th>galaxy</th>\n",
       "      <th>previous</th>\n",
       "      <th>potential</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image know space  god think like people file time system  ... ability  \\\n",
       "count      0    0     0    0     0    0      0    0    0      0  ...       0   \n",
       "unique     0    0     0    0     0    0      0    0    0      0  ...       0   \n",
       "top      NaN  NaN   NaN  NaN   NaN  NaN    NaN  NaN  NaN    NaN  ...     NaN   \n",
       "freq     NaN  NaN   NaN  NaN   NaN  NaN    NaN  NaN  NaN    NaN  ...     NaN   \n",
       "\n",
       "       parallel technique bright modern commit galaxy previous potential  \\\n",
       "count         0         0      0      0      0      0        0         0   \n",
       "unique        0         0      0      0      0      0        0         0   \n",
       "top         NaN       NaN    NaN    NaN    NaN    NaN      NaN       NaN   \n",
       "freq        NaN       NaN    NaN    NaN    NaN    NaN      NaN       NaN   \n",
       "\n",
       "       groupID  \n",
       "count        0  \n",
       "unique       0  \n",
       "top        NaN  \n",
       "freq       NaN  \n",
       "\n",
       "[4 rows x 1001 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"20newsgroups_processed.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m]\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupID\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/vs-workspace/WiSe24/KI/projekt-git/KI-Python/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2414\u001b[0m     )\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,0:1000]\n",
    "\n",
    "y = data[[\"groupID\"]].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3370, 1001)\n",
      "(3370, 1000)\n",
      "(3370,)\n",
      "(2696, 1000)\n",
      "(2696,)\n",
      "(674, 1000)\n",
      "(674,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.6147019863597404\n",
      "Precision:  0.6869533599837496\n",
      "Recall:  0.642433234421365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average='macro'))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='weighted'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code zum Teste welche max_depth die beste bis 200 ist --> 200 ist Erfahrung, nichts wird dann mehr besser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0.23336718067395565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.00      0.00      0.00       159\n",
      "    Graphics       0.31      0.98      0.47       193\n",
      "       Space       0.90      0.31      0.46       197\n",
      "    Religion       0.00      0.00      0.00       125\n",
      "\n",
      "    accuracy                           0.37       674\n",
      "   macro avg       0.30      0.32      0.23       674\n",
      "weighted avg       0.35      0.37      0.27       674\n",
      "\n",
      "2:0.3059842416150827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.53      0.17      0.26       159\n",
      "    Graphics       0.34      0.98      0.50       193\n",
      "       Space       0.91      0.31      0.46       197\n",
      "    Religion       0.00      0.00      0.00       125\n",
      "\n",
      "    accuracy                           0.41       674\n",
      "   macro avg       0.44      0.36      0.31       674\n",
      "weighted avg       0.49      0.41      0.34       674\n",
      "\n",
      "3:0.32464710961005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       1.00      0.04      0.07       159\n",
      "    Graphics       0.34      0.98      0.50       193\n",
      "       Space       0.92      0.31      0.46       197\n",
      "    Religion       0.48      0.18      0.26       125\n",
      "\n",
      "    accuracy                           0.41       674\n",
      "   macro avg       0.69      0.38      0.32       674\n",
      "weighted avg       0.69      0.41      0.34       674\n",
      "\n",
      "4:0.33833714659574904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.15      0.24       159\n",
      "    Graphics       0.88      0.38      0.53       193\n",
      "       Space       0.36      0.97      0.52       197\n",
      "    Religion       0.50      0.03      0.06       125\n",
      "\n",
      "    accuracy                           0.44       674\n",
      "   macro avg       0.57      0.39      0.34       674\n",
      "weighted avg       0.58      0.44      0.37       674\n",
      "\n",
      "5:0.3609512410197733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\lissn\\anaconda3\\envs\\studiumKI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.55      0.16      0.25       159\n",
      "    Graphics       0.87      0.47      0.61       193\n",
      "       Space       0.37      0.97      0.54       197\n",
      "    Religion       0.43      0.02      0.05       125\n",
      "\n",
      "    accuracy                           0.46       674\n",
      "   macro avg       0.56      0.41      0.36       674\n",
      "weighted avg       0.57      0.46      0.40       674\n",
      "\n",
      "6:0.41521658084143936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.30      0.93      0.46       159\n",
      "    Graphics       0.86      0.47      0.61       193\n",
      "       Space       0.93      0.35      0.50       197\n",
      "    Religion       0.67      0.05      0.09       125\n",
      "\n",
      "    accuracy                           0.46       674\n",
      "   macro avg       0.69      0.45      0.42       674\n",
      "weighted avg       0.71      0.46      0.45       674\n",
      "\n",
      "8:0.4194880270679489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.64      0.26      0.37       159\n",
      "    Graphics       0.87      0.52      0.65       193\n",
      "       Space       0.39      0.96      0.56       197\n",
      "    Religion       0.70      0.06      0.10       125\n",
      "\n",
      "    accuracy                           0.50       674\n",
      "   macro avg       0.65      0.45      0.42       674\n",
      "weighted avg       0.64      0.50      0.45       674\n",
      "\n",
      "10:0.4304778443722037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.25      0.35       159\n",
      "    Graphics       0.85      0.54      0.66       193\n",
      "       Space       0.40      0.95      0.57       197\n",
      "    Religion       0.50      0.09      0.15       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.59      0.46      0.43       674\n",
      "weighted avg       0.59      0.51      0.46       674\n",
      "\n",
      "11:0.4341082354777053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.63      0.25      0.35       159\n",
      "    Graphics       0.86      0.55      0.67       193\n",
      "       Space       0.40      0.95      0.56       197\n",
      "    Religion       0.46      0.09      0.15       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.59      0.46      0.43       674\n",
      "weighted avg       0.60      0.51      0.47       674\n",
      "\n",
      "12:0.44074935691211115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.23      0.33       159\n",
      "    Graphics       0.85      0.54      0.66       193\n",
      "       Space       0.41      0.93      0.57       197\n",
      "    Religion       0.40      0.13      0.19       125\n",
      "\n",
      "    accuracy                           0.51       674\n",
      "   macro avg       0.57      0.46      0.44       674\n",
      "weighted avg       0.58      0.51      0.47       674\n",
      "\n",
      "13:0.4756235018629463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.25      0.35       159\n",
      "    Graphics       0.86      0.55      0.68       193\n",
      "       Space       0.42      0.93      0.58       197\n",
      "    Religion       0.50      0.21      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.60      0.49      0.48       674\n",
      "weighted avg       0.61      0.53      0.50       674\n",
      "\n",
      "14:0.4780887670379157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.25      0.35       159\n",
      "    Graphics       0.84      0.56      0.67       193\n",
      "       Space       0.43      0.92      0.58       197\n",
      "    Religion       0.53      0.22      0.31       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.60      0.49      0.48       674\n",
      "weighted avg       0.60      0.53      0.50       674\n",
      "\n",
      "15:0.48237946934808223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.26      0.37       159\n",
      "    Graphics       0.85      0.58      0.69       193\n",
      "       Space       0.42      0.92      0.58       197\n",
      "    Religion       0.53      0.20      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.61      0.49      0.48       674\n",
      "weighted avg       0.61      0.53      0.51       674\n",
      "\n",
      "17:0.48971234292358023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.28      0.38       159\n",
      "    Graphics       0.85      0.56      0.68       193\n",
      "       Space       0.43      0.93      0.59       197\n",
      "    Religion       0.55      0.22      0.31       125\n",
      "\n",
      "    accuracy                           0.54       674\n",
      "   macro avg       0.61      0.50      0.49       674\n",
      "weighted avg       0.62      0.54      0.51       674\n",
      "\n",
      "18:0.5154415766838367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.34      0.85      0.48       159\n",
      "    Graphics       0.85      0.57      0.68       193\n",
      "       Space       0.91      0.46      0.61       197\n",
      "    Religion       0.56      0.19      0.29       125\n",
      "\n",
      "    accuracy                           0.53       674\n",
      "   macro avg       0.66      0.52      0.52       674\n",
      "weighted avg       0.69      0.53      0.54       674\n",
      "\n",
      "20:0.5426763555186807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.33      0.79      0.47       159\n",
      "    Graphics       0.84      0.59      0.69       193\n",
      "       Space       0.93      0.47      0.62       197\n",
      "    Religion       0.58      0.30      0.39       125\n",
      "\n",
      "    accuracy                           0.54       674\n",
      "   macro avg       0.67      0.53      0.54       674\n",
      "weighted avg       0.70      0.54      0.56       674\n",
      "\n",
      "23:0.5427497653179365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.37      0.46       159\n",
      "    Graphics       0.86      0.61      0.71       193\n",
      "       Space       0.47      0.89      0.61       197\n",
      "    Religion       0.56      0.29      0.38       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.63      0.54      0.54       674\n",
      "weighted avg       0.63      0.58      0.56       674\n",
      "\n",
      "25:0.5463225922887875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.40      0.48       159\n",
      "    Graphics       0.85      0.62      0.72       193\n",
      "       Space       0.48      0.88      0.62       197\n",
      "    Religion       0.56      0.27      0.37       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.62      0.54      0.55       674\n",
      "weighted avg       0.63      0.58      0.57       674\n",
      "\n",
      "26:0.5477942690275176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.40      0.48       159\n",
      "    Graphics       0.84      0.61      0.71       193\n",
      "       Space       0.48      0.90      0.62       197\n",
      "    Religion       0.59      0.28      0.38       125\n",
      "\n",
      "    accuracy                           0.58       674\n",
      "   macro avg       0.63      0.55      0.55       674\n",
      "weighted avg       0.63      0.58      0.57       674\n",
      "\n",
      "27:0.5610504411099342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.40      0.48       159\n",
      "    Graphics       0.85      0.62      0.72       193\n",
      "       Space       0.49      0.90      0.63       197\n",
      "    Religion       0.61      0.31      0.41       125\n",
      "\n",
      "    accuracy                           0.59       674\n",
      "   macro avg       0.64      0.56      0.56       674\n",
      "weighted avg       0.64      0.59      0.58       674\n",
      "\n",
      "28:0.5733614693886971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.63      0.40      0.49       159\n",
      "    Graphics       0.85      0.63      0.72       193\n",
      "       Space       0.49      0.87      0.63       197\n",
      "    Religion       0.60      0.37      0.46       125\n",
      "\n",
      "    accuracy                           0.60       674\n",
      "   macro avg       0.64      0.57      0.57       674\n",
      "weighted avg       0.64      0.60      0.59       674\n",
      "\n",
      "35:0.5847935580303225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.62      0.43      0.51       159\n",
      "    Graphics       0.83      0.68      0.75       193\n",
      "       Space       0.52      0.86      0.64       197\n",
      "    Religion       0.58      0.36      0.44       125\n",
      "\n",
      "    accuracy                           0.61       674\n",
      "   macro avg       0.63      0.58      0.58       674\n",
      "weighted avg       0.64      0.61      0.60       674\n",
      "\n",
      "44:0.5863667860646924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.43      0.50       159\n",
      "    Graphics       0.86      0.74      0.79       193\n",
      "       Space       0.53      0.89      0.66       197\n",
      "    Religion       0.58      0.29      0.39       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.64      0.59      0.59       674\n",
      "weighted avg       0.65      0.63      0.61       674\n",
      "\n",
      "46:0.5876104379400323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.58      0.39      0.47       159\n",
      "    Graphics       0.84      0.72      0.78       193\n",
      "       Space       0.53      0.87      0.66       197\n",
      "    Religion       0.57      0.37      0.45       125\n",
      "\n",
      "    accuracy                           0.62       674\n",
      "   macro avg       0.63      0.59      0.59       674\n",
      "weighted avg       0.64      0.62      0.61       674\n",
      "\n",
      "54:0.5944085347317221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.42      0.49       159\n",
      "    Graphics       0.86      0.74      0.79       193\n",
      "       Space       0.54      0.88      0.67       197\n",
      "    Religion       0.56      0.34      0.42       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.64      0.59      0.59       674\n",
      "weighted avg       0.65      0.63      0.62       674\n",
      "\n",
      "65:0.5951784347251003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.59      0.43      0.50       159\n",
      "    Graphics       0.81      0.77      0.79       193\n",
      "       Space       0.56      0.84      0.67       197\n",
      "    Religion       0.55      0.34      0.42       125\n",
      "\n",
      "    accuracy                           0.63       674\n",
      "   macro avg       0.63      0.60      0.60       674\n",
      "weighted avg       0.64      0.63      0.62       674\n",
      "\n",
      "69:0.606299126743449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.47      0.53       159\n",
      "    Graphics       0.80      0.75      0.77       193\n",
      "       Space       0.57      0.85      0.68       197\n",
      "    Religion       0.58      0.35      0.44       125\n",
      "\n",
      "    accuracy                           0.64       674\n",
      "   macro avg       0.64      0.61      0.61       674\n",
      "weighted avg       0.65      0.64      0.63       674\n",
      "\n",
      "80:0.6147019863597404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.60      0.52      0.55       159\n",
      "    Graphics       0.83      0.74      0.78       193\n",
      "       Space       0.57      0.83      0.67       197\n",
      "    Religion       0.58      0.37      0.45       125\n",
      "\n",
      "    accuracy                           0.64       674\n",
      "   macro avg       0.64      0.61      0.61       674\n",
      "weighted avg       0.65      0.64      0.63       674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "i_mem = 0\n",
    "for i in range(200):\n",
    "    if(i==0):\n",
    "        continue\n",
    "    clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=i)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predict = clf.predict(X_test)\n",
    "    if f1_score(predict, y_test, average='macro')>f:\n",
    "        f = f1_score(predict, y_test, average='macro')\n",
    "        i_mem = i\n",
    "        print(str(i_mem)+\":\"+str(f))\n",
    "        report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "        print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cdoe zum Testen welche Gewichtung der Klassen die Beste ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.6250351364321953\n",
      "Precision:  0.6253301288811098\n",
      "Recall:  0.6500917090775308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Atheism       0.61      0.49      0.55       159\n",
      "    Graphics       0.81      0.76      0.79       193\n",
      "       Space       0.61      0.87      0.72       197\n",
      "    Religion       0.57      0.38      0.45       125\n",
      "\n",
      "    accuracy                           0.66       674\n",
      "   macro avg       0.65      0.63      0.63       674\n",
      "weighted avg       0.66      0.66      0.65       674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0: 'atheism' 1: 'graphics' 2: 'space' 3: 'religion.misc'\n",
    "class_weights = {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n",
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion=\"entropy\", max_depth=80, class_weight=class_weights)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"F-Score: \",f1_score(predict, y_test, average=\"macro\"))\n",
    "print(\"Precision: \",precision_score(predict, y_test, average='macro'))\n",
    "print(\"Recall: \",recall_score(predict, y_test, average='macro'))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "report = classification_report(y_test, predict, target_names=[\"Atheism\", \"Graphics\", \"Space\", \"Religion\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}:0.6147019863597404\n",
      "{0: 1.0, 1: 3.0, 2: 4.0, 3: 1.0}:0.6246210009246238\n",
      "{0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}:0.6250351364321953\n",
      "Bester F1-Score: 0.6250351364321953\n",
      "Beste class_weights: {0: 4.0, 1: 4.0, 2: 5.0, 3: 2.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# MÃ¶gliche Gewichtswerte zwischen 1.0 und 5.0 in 0.5-Schritten\n",
    "weight_values = np.arange(1.0, 5.1, 1)\n",
    "\n",
    "# Generiere alle Kombinationen der Gewichtswerte fÃ¼r vier Klassen\n",
    "all_combinations = list(itertools.product(weight_values, repeat=4))\n",
    "\n",
    "# Initialisiere die Variablen zur Speicherung des besten Scores und der besten Gewichte\n",
    "best_f1_score = 0.0\n",
    "best_class_weights = None\n",
    "\n",
    "for weights in all_combinations:\n",
    "    # Definiere ein Dictionary fÃ¼r die Gewichtung jeder Klasse\n",
    "    class_weights = {0: weights[0], 1: weights[1], 2: weights[2], 3: weights[3]}\n",
    "    \n",
    "    # Initialisiere und trainiere den Entscheidungsbaum mit den definierten class_weights\n",
    "    clf = DecisionTreeClassifier(class_weight=class_weights, random_state=42, criterion=\"entropy\", max_depth=80)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Mache Vorhersagen und berechne die Metriken\n",
    "    predictions = clf.predict(X_test)\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # PrÃ¼fe, ob der aktuelle F1-Score besser ist als der bisher beste\n",
    "    current_f1_score = report['macro avg']['f1-score']\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_class_weights = class_weights\n",
    "        print(str(best_class_weights)+\":\"+str(best_f1_score))\n",
    "\n",
    "# Ausgabe der besten Gewichtung und des besten F1-Scores\n",
    "print(\"Bester F1-Score:\", best_f1_score)\n",
    "print(\"Beste class_weights:\", best_class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
