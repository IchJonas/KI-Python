{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard-Bibliotheken\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn: Modellselektion und Validierung\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scikit-learn: Feature-Engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Scikit-learn: Modelle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree \n",
    "\n",
    "\n",
    "\n",
    "# Scikit-learn: Metriken\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Scikit-learn: Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Warnungen ignorieren\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# System\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 1: Laden Preprocess dateien (Daten Test u. Train seperat)\n",
    "- inkl. Aufteilung X_train, X_test, y_train, y_test, X_dev, y_dev\n",
    "- Bereitet die Trainings-, Test- und Validierungsdaten vor.\n",
    "    Args:\n",
    "        train_file (str): Pfad zur CSV-Datei der Trainingsdaten.\n",
    "        test_file (str): Pfad zur CSV-Datei der Testdaten.\n",
    "    Returns:\n",
    "        tuple: Enthält die Trainingsdaten (X_train, y_train), \n",
    "               Testdaten (X_test, y_test) und \n",
    "               Validierungsdaten (X_dev, y_dev)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_file, test_file):\n",
    "    # Daten laden\n",
    "    data_train = pd.read_csv(train_file, on_bad_lines='skip', sep=';')\n",
    "    data_test = pd.read_csv(test_file, on_bad_lines='skip', sep=';')\n",
    "\n",
    "    # Features und Labels extrahieren\n",
    "    X_train = data_train['text']\n",
    "    y_train = data_train['group']\n",
    "    X_test = data_test['text']\n",
    "    y_test = data_test['group']\n",
    "\n",
    "    # Testdaten in Test- und Validierungsdaten aufteilen\n",
    "    X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "        X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test), (X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPT 1.1: Ausführung der prepare_data(): Laden dataLemmaLowerStop_train manuell\n",
    "- Muss nicht ausgeführt werden wenn calculate_f1_macro() ausgeführt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: (2624,) (2624,)\n",
      "Testdaten: (328,) (328,)\n",
      "Validierungsdaten: (328,) (328,)\n"
     ]
    }
   ],
   "source": [
    "train_file = \"preprocessed/dataLemmaLowerStop_train.csv\"\n",
    "test_file = \"preprocessed/dataLemmaLowerStop_test.csv\"\n",
    "\n",
    "(X_train, y_train), (X_test, y_test), (X_dev, y_dev) = prepare_data(train_file, test_file)\n",
    "\n",
    "print(\"Trainingsdaten:\", X_train.shape, y_train.shape)\n",
    "print(\"Testdaten:\", X_test.shape, y_test.shape)\n",
    "print(\"Validierungsdaten:\", X_dev.shape, y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPT 1.2: Ausführung der prepare_data(): Laden dataLemmaLemmaStopNouns_train manuell\n",
    "- Muss nicht ausgeführt werden wenn calculate_f1_macro() ausgeführt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"preprocessed/dataLemmaLowerStopNouns_train.csv\"\n",
    "test_file = \"preprocessed/dataLemmaLowerStopNouns_test.csv\"\n",
    "\n",
    "(X_train, y_train), (X_test, y_test), (X_dev, y_dev) = prepare_data(train_file, test_file)\n",
    "\n",
    "print(\"Trainingsdaten:\", X_train.shape, y_train.shape)\n",
    "print(\"Testdaten:\", X_test.shape, y_test.shape)\n",
    "print(\"Validierungsdaten:\", X_dev.shape, y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 2 (Alte Variante): Laden Preprocess datei (Daten Test u. Train zsm.)\n",
    "- inkl. Aufteilung X_train, X_test, y_train, y_test, X_dev, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"preprocessed/dataLemmaLowerStop.csv\", on_bad_lines='skip', sep=';')\n",
    "data = data.iloc[:,1:3]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text'], data['group'], test_size=0.2, random_state=42, stratify=data['group']\n",
    ")\n",
    "\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT 3 (Alte Variante): Laden 20newgroups unprocessed\n",
    "- inkl. Aufteilung X_train, X_test, y_train, y_test, X_dev, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"20 newsgroups/20newsgroups.csv\", on_bad_lines='skip', sep=';')\n",
    "data = data.dropna()\n",
    "data = data.drop_duplicates()\n",
    "data = data.iloc[:,1:3]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text'], data['group'], test_size=0.2, random_state=42, stratify=data['group']\n",
    ")\n",
    "\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Classifier ermittlung bester clf und tree Params (RandomizedSearchCV)\n",
    "- Um herauszufinden welche Parameter mit GridSearchCV genauer untersucht werden müssen\n",
    "- Zum testet n zufälliger Kombinationen der angegebenen tfidf und clf Parametern (n_iter), um eine Kombination mit gutem F1 Wert zu finden\n",
    "- Verwendung Pipelin um TF-IDF-Vektorisierung und TreeClassifier zu vereinheitlichen\n",
    "\n",
    "Erkentnisse:\n",
    "- clf__criterion gini beim trainieren mit vektoren immer am besten\n",
    "- min_sample_split 2 am besten\n",
    "- min saplee_leaf 1 am besten\n",
    "\n",
    "Erklärungen Parameter:\n",
    "    Params TfidfVectorizer:\n",
    "        - tfidf__max_df: Maximale Häufigkeit eines Begriffs in Dokumenten.\n",
    "        - tfidf__min_df: Minimale Häufigkeit eines Begriffs in Dokumenten.\n",
    "        - tfidf__max_features: Maximale Anzahl der zu extrahierenden Begriffe.\n",
    "        - tfidf__sublinear_tf eine Möglichkeit, die Bedeutung häufiger Begriffe in den Dokumenten zu dämpfen\n",
    "        - clf__max_depth: Maximale Tiefe des Entscheidungsbaums.\n",
    "        - clf__min_samples_split: Minimale Anzahl an Proben, um einen Knoten zu teilen.\n",
    "        - clf__criterion: Bewertungsfunktion für den Entscheidungsbaum. (entropy:feiner; gini:grober)\n",
    "        - clf__min_samples_leaf: Minimale Anzahl an Proben in einem Blatt des Entscheidungsbaums.\n",
    "    \n",
    "    Params RandomizedSearchCV:\n",
    "        - CV: Technik, um die Leistung eines Modells besser zu bewerten und Überanpassung (Overfitting) zu vermeiden. Dabei wird der verfügbare Datensatz in mehrere Teile (sogenannte Folds) aufgeteilt, und das Modell wird mehrfach trainiert und getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_df=0.8,\n",
    "        min_df=2,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        max_features=5000,\n",
    "    )),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'tfidf__max_df': [0.1, 0.2, 0.5, 0.7, 0.8, 0.9],\n",
    "    'tfidf__min_df': [1, 2, 5],\n",
    "    'tfidf__max_features': [500, 1000, 3000, 5000, 10000, 15000, None],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'clf__max_depth': [60, 130, 140, 150, 160, 180, 200], \n",
    "    'clf__min_samples_split': [2, 3],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__criterion': ['gini'],          \n",
    "\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,                   # Anzahl der zu testenden zufälligen Kombinationen\n",
    "    cv=5,                         # 5-fache Cross-Validation\n",
    "    scoring='f1_macro',           # Optimierung auf F1-Score (macro)\n",
    "    random_state=42,              # Zufälligkeit kontrollieren\n",
    "    n_jobs=-1                     # Parallele Verarbeitung\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "y_dev_pred = best_pipeline.predict(X_dev)\n",
    "\n",
    "print(\"F1-Score: \", f1_score(y_dev, y_dev_pred, average='macro'))\n",
    "print(\"Precision: \", precision_score(y_dev, y_dev_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_dev, y_dev_pred, average='macro'))\n",
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Classifier ermittlung bester clf und tree Params (GridSearchCV)\n",
    "\n",
    "- Zum genauen testen aller Kombinationen der angegebenen tfidf und clf Parametern, um die mit dem besten F1 Wert zu finden\n",
    "- Verwendung Pipelin um TF-IDF-Vektorisierung und TreeClassifier zu vereinheitlichen\n",
    "\n",
    "\n",
    "Erklärungen Paramerter:\n",
    "    Params TfidfVectorizer:\n",
    "        - tfidf__max_df: Maximale Häufigkeit eines Begriffs in Dokumenten.\n",
    "        - tfidf__min_df: Minimale Häufigkeit eines Begriffs in Dokumenten.\n",
    "        - tfidf__max_features: Maximale Anzahl der zu extrahierenden Begriffe.\n",
    "        - tfidf__sublinear_tf eine Möglichkeit, die Bedeutung häufiger Begriffe in den Dokumenten zu dämpfen\n",
    "        - clf__max_depth: Maximale Tiefe des Entscheidungsbaums.\n",
    "        - clf__min_samples_split: Minimale Anzahl an Proben, um einen Knoten zu teilen.\n",
    "        - clf__criterion: Bewertungsfunktion für den Entscheidungsbaum. (entropy:feiner; gini:grober)\n",
    "        - clf__min_samples_leaf: Minimale Anzahl an Proben in einem Blatt des Entscheidungsbaums.\n",
    "    \n",
    "    Params RandomizedSearchCV:\n",
    "        - CV: Technik, um die Leistung eines Modells besser zu bewerten und Überanpassung (Overfitting) zu vermeiden. Dabei wird der verfügbare Datensatz in mehrere Teile (sogenannte Folds) aufgeteilt, und das Modell wird mehrfach trainiert und getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_macro_grid(train_file, test_file):\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test), (X_dev, y_dev) = prepare_data(train_file, test_file)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_df=0.8,\n",
    "        min_df=2,\n",
    "        ngram_range=(1, 1), #TODO Anpassen für kontext => bisher (1,1) bestes Ergebnis\n",
    "        stop_words='english',\n",
    "        max_features=5000\n",
    "    )),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'tfidf__max_df': [0.05, 0.1, 0.15, 0.3],             \n",
    "    #     'tfidf__min_df': [1, 2],                 \n",
    "    #     'tfidf__max_features': [4500, 5000, 5600], \n",
    "    #     'tfidf__sublinear_tf': [True, False],           \n",
    "    #     'clf__min_samples_split': [2, 3],           \n",
    "    #     'clf__min_samples_leaf': [1, 2],            \n",
    "    #     'clf__max_depth': [130, 190, 200],        \n",
    "    #     'clf__criterion': ['gini'],          \n",
    "    # }\n",
    "\n",
    "    param_grid = {\n",
    "        'tfidf__max_df': [0.05, 0.1, 0.3, 0.5],             \n",
    "        'tfidf__min_df': [2],                 \n",
    "        'tfidf__max_features': [500, 2500, 5600], \n",
    "        'tfidf__sublinear_tf': [True],           \n",
    "        'clf__min_samples_split': [2],           \n",
    "        'clf__min_samples_leaf': [1],            \n",
    "        'clf__max_depth': [80, 130, 200],        \n",
    "        'clf__criterion': ['gini'],          \n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,                          # 5-fache Cross-Validation\n",
    "        scoring='f1_macro',            # Optimierung auf F1-Score (macro)\n",
    "        n_jobs=-1                      # Parallele Verarbeitung\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_dev_pred = best_pipeline.predict(X_dev)\n",
    "    \n",
    "    f1_macro = f1_score(y_dev, y_dev_pred, average='macro')\n",
    "    precision_macro = precision_score(y_dev, y_dev_pred, average='macro')\n",
    "    recall_macro = recall_score(y_dev, y_dev_pred, average='macro')\n",
    "    report = classification_report(y_dev, y_dev_pred)\n",
    "    return f1_macro, precision_macro, recall_macro, report, pipeline, X_test, y_test, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_f1_macro_grid() Methode zum berechnen des Tree Classifier mit Vektor (ohne Search)\n",
    "- Zum testen der momentan besten Parameter \n",
    "- Parameter müssen direkt in Methode eintragen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'clf__criterion': 'gini', 'clf__max_depth': 200, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'tfidf__max_df': 0.05, 'tfidf__max_features': 5600, 'tfidf__min_df': 2, 'tfidf__sublinear_tf': True}\n",
      "F1-Score:  0.6960569199640945\n",
      "Precision:  0.7128091328815769\n",
      "Recall:  0.6923751686909582\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        78\n",
      "           1       0.84      0.80      0.82        95\n",
      "           2       0.62      0.81      0.70        95\n",
      "           3       0.69      0.63      0.66        60\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.71      0.69      0.70       328\n",
      "weighted avg       0.72      0.71      0.70       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = \"preprocessed/dataLemmaLowerStop_train.csv\"\n",
    "test_file = \"preprocessed/dataLemmaLowerStop_test.csv\"\n",
    "\n",
    "f1_macro, precision_macro, recall_macro, report, pipeline, X_test, y_test, best_params = calculate_f1_macro_grid(train_file, test_file)\n",
    "\n",
    "print(\"Beste Parameter:\", best_params)\n",
    "print(\"F1-Score: \", f1_macro)\n",
    "print(\"Precision: \", precision_macro)\n",
    "print(\"Recall: \", recall_macro)\n",
    "print(\"Report: \", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_macro(train_file, test_file):\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test), (X_dev, y_dev) = prepare_data(train_file, test_file)\n",
    "\n",
    "    # Nach Probe mit dataLemmaLowerStop.csv sind das die besten Parameter \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            min_df=2,\n",
    "            max_features=5600,\n",
    "            ngram_range=(1, 1),\n",
    "            max_df=0.05,\n",
    "            stop_words='english'\n",
    "        )),\n",
    "        ('clf', DecisionTreeClassifier(\n",
    "            random_state=42,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_depth=200,\n",
    "            criterion='gini'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_dev_pred = pipeline.predict(X_dev)\n",
    "    f1_macro = f1_score(y_dev, y_dev_pred, average='macro')\n",
    "    precision_macro = precision_score(y_dev, y_dev_pred, average='macro')\n",
    "    recall_macro = recall_score(y_dev, y_dev_pred, average='macro')\n",
    "    report = classification_report(y_dev, y_dev_pred)\n",
    "    return f1_macro, precision_macro, recall_macro, report, pipeline, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_f1_macro() Methode zum berechnen des Tree Classifier mit Vektor (ohne Search)\n",
    "- Zum testen der momentan besten Parameter \n",
    "- Parameter müssen direkt in Methode eintragen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_macro(train_file, test_file):\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test), (X_dev, y_dev) = prepare_data(train_file, test_file)\n",
    "\n",
    "    # Nach Probe mit dataLemmaLowerStop.csv sind das die besten Parameter \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            min_df=2,\n",
    "            max_features=5600,\n",
    "            ngram_range=(1, 1),\n",
    "            max_df=0.05,\n",
    "            stop_words='english'\n",
    "        )),\n",
    "        ('clf', DecisionTreeClassifier(\n",
    "            random_state=42,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_depth=200,\n",
    "            criterion='gini'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_dev_pred = pipeline.predict(X_dev)\n",
    "    f1_macro = f1_score(y_dev, y_dev_pred, average='macro')\n",
    "    precision_macro = precision_score(y_dev, y_dev_pred, average='macro')\n",
    "    recall_macro = recall_score(y_dev, y_dev_pred, average='macro')\n",
    "    report = classification_report(y_dev, y_dev_pred)\n",
    "    return f1_macro, precision_macro, recall_macro, report, pipeline, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methode calculate_f1_macro Ausführen\n",
    "- Ausgabe der f1_macro, precision_macro, recall_macro, pred werte für die in der Methode festgelegten Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.6960569199640945\n",
      "Precision:  0.7128091328815769\n",
      "Recall:  0.6923751686909582\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        78\n",
      "           1       0.84      0.80      0.82        95\n",
      "           2       0.62      0.81      0.70        95\n",
      "           3       0.69      0.63      0.66        60\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.71      0.69      0.70       328\n",
      "weighted avg       0.72      0.71      0.70       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = \"preprocessed/dataLemmaLowerStop_train.csv\"\n",
    "test_file = \"preprocessed/dataLemmaLowerStop_test.csv\"\n",
    "\n",
    "f1_macro, precision_macro, recall_macro, report, pipeline, X_test, y_test = calculate_f1_macro(train_file, test_file)\n",
    "\n",
    "print(\"F1-Score: \", f1_macro)\n",
    "print(\"Precision: \", precision_macro)\n",
    "print(\"Recall: \", recall_macro)\n",
    "print(\"Report: \", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mit festen tree u. tfidf param für alle preprocesse Dateien\n",
    "- Emittelt welche Preprocess Datei den besten F1 Score hat und gibt diesen aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_directory(directory):\n",
    "    train_files = [os.path.join(directory, f) for f in os.listdir(directory) if 'train' in f and f.endswith('.csv')]\n",
    "    test_files = [os.path.join(directory, f) for f in os.listdir(directory) if 'test' in f and f.endswith('.csv')]\n",
    "    results = pd.DataFrame(columns=[\"Train-Datei\", \"Test-Datei\", \"F1-Score\", \"Precision\", \"Recall\"])\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_file = None\n",
    "    \n",
    "    total_files = len(train_files)\n",
    "    \n",
    "    for i, train_file in enumerate(train_files, start=1):\n",
    "        test_file = next((f for f in test_files if os.path.basename(train_file).replace('train', 'test') in f), None)\n",
    "        if not test_file:\n",
    "            print(f\"Keine passende Testdatei für {train_file} gefunden, übersprungen.\")\n",
    "            continue\n",
    "        \n",
    "        progress = (i / total_files) * 100\n",
    "        bar_length = 50\n",
    "        filled_length = int(bar_length * i // total_files)\n",
    "        bar = f\"[{'#' * filled_length}{'.' * (bar_length - filled_length)}]\"\n",
    "        sys.stdout.write(f\"\\r{bar} {progress:.2f}% ({i}/{total_files})\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        f1, precision, recall, report, pipeline,_,_ = calculate_f1_macro(train_file, test_file)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame({\n",
    "            \"Train-Datei\": [train_file],\n",
    "            \"F1-Score\": [f1],\n",
    "            \"Precision\": [precision],\n",
    "            \"Recall\": [recall]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_file = train_file\n",
    "            best_report = report\n",
    "    \n",
    "    results = results.sort_values(by=\"F1-Score\", ascending=False)\n",
    "    print(\"\\nErgebnisse:\")\n",
    "    top_5 = results.head(5)\n",
    "    print(\"\\nTop 5 Ergebnisse:\")\n",
    "    print(top_5)\n",
    "\n",
    "    print(f\"\\nBester F1-Score: {best_f1}\")\n",
    "    print(f\"Beste Datei: {best_file}\")\n",
    "    print(f\"Report: {best_report}\")\n",
    "    return f1_macro, precision_macro, recall_macro, report, pipeline\n",
    "\n",
    "directory = \"preprocessed/\"\n",
    "f1_macro, precision_macro, recall_macro, report, pipeline = train_on_directory(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ermittlung endgültiger F1-Score (an ungesehenen Testdaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO prüfen ob alle variablen korrekt verwewdet werden\n",
    "y_dev_pred = pipeline.predict(X_test)\n",
    "print(\"F1-Score: \", f1_score(y_test, y_dev_pred, average='macro'))\n",
    "print(\"Precision: \", precision_score(y_test, y_dev_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test, y_dev_pred, average='macro'))\n",
    "print(classification_report(y_test, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancewerte nach Training mit TreeClassifier ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.named_steps['clf']  \n",
    "tfidf = pipeline.named_steps['tfidf']  \n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Wichtigste Features:\")\n",
    "print(importance_df.head(25))\n",
    "\n",
    "importance_df.head(10).plot(kind=\"bar\", x=\"Feature\", y=\"Importance\", legend=False)\n",
    "plt.title(\"Top 10 wichtige Features im Entscheidungsbaum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Speichern TFIDF-Matrix in csv\n",
    "- TODO: DataTrain public machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pipeline.named_steps['tfidf']\n",
    "\n",
    "tfidf_matrix = tfidf.transform(X_train)\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), \n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "\n",
    "tfidf_df.to_csv(\"tfidf_matrix.csv\", index=False, sep=';')\n",
    "print(\"TF-IDF-Matrix wurde gespeichert.\")\n",
    "\n",
    "print(tfidf_df.head())\n",
    "\n",
    "\n",
    "data_train['average_tfidf'] = tfidf_matrix.mean(axis=1)\n",
    "average_per_class = data_train.groupby('group')['average_tfidf'].mean()\n",
    "print(\"\\nDurchschnittliche TF-IDF-Werte pro Klasse:\\n\", average_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Histogramm Verteilung der TF-IDF-Werte plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_values = tfidf_df.values.flatten()\n",
    "\n",
    "plt.hist(tfidf_values, bins=50, color='blue', edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Häufigkeitsverteilung der TF-IDF-Werte\")\n",
    "plt.xlabel(\"TF-IDF-Wert\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.yscale('log')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Entscheidungsbaum ploten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.named_steps['clf']  \n",
    "tfidf = pipeline.named_steps['tfidf']  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "tree.plot_tree(clf,feature_names=list(tfidf.get_feature_names_out()), fontsize=10, max_depth=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
