{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainMan ist für das manuelle Traninieren auf eine csv. Dabei kann ausgewählt werden, welches der Hyperparameter optimiert werden soll. \n",
    "Es gibt auch die Option mit train alle zur Verfügung stehndende Parameter zu optimieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainMan:\n",
    "    def __init__(self, path, \n",
    "                 max_depthVal=None, max_depthMax=200, max_depthMin=0, \n",
    "                 min_sample_splitVal = 2, min_sample_splitMax=10, min_sample_splitMin=2, \n",
    "                 clf=None, criterionVal=\"entropy\"):\n",
    "        self.path = path\n",
    "        self.trainList = self.__data()\n",
    "        self.max_depthVal = max_depthVal\n",
    "        self.max_depthMax = max_depthMax\n",
    "        self.max_depthMin=max_depthMin\n",
    "        self.min_sample_splitMax = min_sample_splitMax\n",
    "        self.min_sample_splitMin = min_sample_splitMin\n",
    "        self.min_sample_splitVal = min_sample_splitVal\n",
    "        self.clf = clf\n",
    "        self.criterionVal = criterionVal\n",
    "        self.results = np.empty((3, max_depthMax-max_depthMin, min_sample_splitMax-min_sample_splitMin, 3))\n",
    "    def __data(self):\n",
    "        self.data = pd.read_csv(self.path)\n",
    "        columnsLength = self.data.shape[1]-1\n",
    "        X = self.data.iloc[:,0:columnsLength]\n",
    "        y = self.data[[\"groupID\"]].values.ravel()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        return [self.X_train, self.X_test, self.y_train, self.y_test]\n",
    "    def get_X_train(self):\n",
    "        return self.X_train\n",
    "    def out(self):\n",
    "        if(self.clf == None):\n",
    "            print(\"Modell ohne Parameter wird angelegt, da keines vorhanden:\")\n",
    "            self.clf = DecisionTreeClassifier(random_state=42)\n",
    "            self.clf = self.clf.fit(self.trainList[0], self.trainList[2])\n",
    "        predict = self.clf.predict(self.trainList[1])\n",
    "        report = classification_report(self.trainList[3], predict, target_names=[\"Atheism\",\"Graphics\", \"Space\", \"Religion\"])\n",
    "        #print(report)\n",
    "        #print(\"F-Score: \",f1_score(predict, self.trainList[3], average='macro'))\n",
    "        #print(\"Precision: \",precision_score(predict, self.trainList[3], average='macro'))\n",
    "        #print(\"Recall: \",recall_score(predict, self.trainList[3], average='macro'))\n",
    "        return f1_score(predict, self.trainList[3], average='macro'), precision_score(predict, self.trainList[3], average='macro'), recall_score(predict, self.trainList[3], average='macro')\n",
    "    def max_depth(self, min, max):\n",
    "        self.max_depthMax = max\n",
    "        self.max_depthMin = min\n",
    "        f = 0\n",
    "        for i in range(self.max_depthMax):\n",
    "            if(i<self.max_depthMin):\n",
    "                continue\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, max_depth=i, min_samples_split=self.min_sample_splitVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.max_depthVal = i\n",
    "                self.clf =  DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, max_depth=i, min_samples_split=self.min_sample_splitVal)\n",
    "                self.clf = self.clf.fit(self.trainList[0], self.trainList[2])      \n",
    "        return self.max_depthVal\n",
    "    def tree(self):\n",
    "            self.clf = DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, max_depth=self.max_depthVal)\n",
    "            self.clf = self.clf.fit(self.trainList[0], self.trainList[2])  \n",
    "            return self.clf  \n",
    "    def random_state(self, max, min):\n",
    "        f = 0\n",
    "        random = None\n",
    "        for i in range(max):\n",
    "            if(i<min):\n",
    "                continue\n",
    "            clf = DecisionTreeClassifier(random_state=i, criterion=self.criterionVal, max_depth=85, min_samples_split=self.min_sample_splitVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                random = i\n",
    "                self.clf =  DecisionTreeClassifier(random_state=random, criterion=self.criterionVal, max_depth=93, min_samples_split=self.min_sample_splitVal)\n",
    "                self.clf = self.clf.fit(self.trainList[0], self.trainList[2])      \n",
    "        return random\n",
    "    def min_sample_split(self):\n",
    "        f = 0\n",
    "        for i in range(self.min_sample_splitMax):\n",
    "            if(i<self.min_sample_splitMin):\n",
    "                continue\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=self.criterionVal, min_samples_split=i, max_depth=self.max_depthVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.min_sample_splitVal = i    \n",
    "        return self.min_sample_splitVal\n",
    "    def criterion(self):\n",
    "        criterionList = {\"entropy\", \"log_loss\", \"gini\"}\n",
    "        f = 0\n",
    "        for criterion in criterionList:\n",
    "            clf = DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=self.min_sample_splitVal, max_depth=self.max_depthVal)\n",
    "            clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "            predict = clf.predict(self.trainList[1])\n",
    "            if f1_score(predict, self.trainList[3], average='macro')>f:\n",
    "                f = f1_score(predict, self.trainList[3], average='macro')\n",
    "                self.criterionVal = criterion\n",
    "                self.clf =  DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=self.min_sample_splitVal, max_depth=self.max_depthVal)\n",
    "                self.clf = self.clf.fit(self.trainList[0], self.trainList[2])\n",
    "        return self.criterionVal  \n",
    "    def train(self):\n",
    "        criterionList = {\"entropy\", \"log_loss\", \"gini\"}\n",
    "        for criterion in criterionList:\n",
    "            if (criterion == \"entropy\"):\n",
    "                index = 0\n",
    "            elif (criterion==\"log_loss\"):\n",
    "                index = 1\n",
    "            else:\n",
    "                index = 2\n",
    "            for depth in range(self.max_depthMax):\n",
    "                if(depth < self.max_depthMin):\n",
    "                    continue\n",
    "                for min_split in range (self.min_sample_splitMax):\n",
    "                    if (min_split<self.min_sample_splitMin):\n",
    "                        continue\n",
    "                    clf = DecisionTreeClassifier(random_state=42, criterion=criterion, min_samples_split=min_split, max_depth=depth)\n",
    "                    clf = clf.fit(self.trainList[0], self.trainList[2])\n",
    "                    predict = clf.predict(self.trainList[1])\n",
    "                    print(str(index)+\"|\"+str(depth)+\"|\"+str(min_split))\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 0] = f1_score(predict, self.trainList[3], average='macro')\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 1] = precision_score(predict, self.trainList[3], average='macro')\n",
    "                    self.results[index, depth-self.max_depthMin, min_split-self.min_sample_splitMin, 2] = recall_score(predict, self.trainList[3], average='macro')\n",
    "        index = np.unravel_index(np.argmax(self.results[:, :, :, 0]), self.results[:, :, :, 0].shape)\n",
    "        if (index[0] == 0):\n",
    "            self.criterionVal = \"entropy\"\n",
    "        elif (index[0]==1):\n",
    "            self.criterionVal = \"log_loss\"\n",
    "        else:\n",
    "            self.criterionVal = \"gini\"\n",
    "        self.max_depthVal = index[1]+self.max_depthMin\n",
    "        self.min_sample_splitVal = index[2]+self.min_sample_splitMin\n",
    "        print(self.criterionVal+\"|\"+str(self.max_depthVal)+\"|\"+str(self.min_sample_splitVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainAuto optimiert nur auf max_depth, dafür auf meherere Dateein, dabei kann dann am Besten der vielversprechneste Ansatz herausgefunden werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainAuto:\n",
    "    def __init__(self, path):\n",
    "        self.paths = [os.path.relpath(os.path.join(path, datei)) for datei in os.listdir(path) if os.path.isfile(os.path.join(path, datei))]\n",
    "        self.data = pd.DataFrame(columns=[\"Datei\", \"criterion\", \"max_depth\", \"min_sample_split\", \"f_score\", \"precision\", \"recall\"])\n",
    "    \n",
    "    def __save(self):\n",
    "        self.data.to_csv(\"trainAuto3.csv\", index=False, encoding=\"utf-8\")\n",
    "        print(\"\\nData gesichert\")\n",
    "    \n",
    "    def train(self):\n",
    "        gesamt = len(self.paths)\n",
    "        \n",
    "        for i, path in enumerate(self.paths, start=1):\n",
    "            prozent = (i / gesamt) * 100\n",
    "            länge = 50\n",
    "            balken_länge = int(länge * i // gesamt)\n",
    "            balken = f\"[{'#' * balken_länge}{'.' * (länge - balken_länge)}]\"\n",
    "            sys.stdout.write(f\"\\r{balken} {prozent:.2f}% ({i}/{gesamt})\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            tree = trainMan(path=path, criterionVal=\"entropy\")\n",
    "            max_depth = tree.max_depth(50, 150)\n",
    "            f_score, precision, recall = tree.out()\n",
    "            \n",
    "            self.data = pd.concat([self.data, pd.DataFrame({\n",
    "                \"Datei\": [path], \n",
    "                \"criterion\": [\"entropy\"], \n",
    "                \"max_depth\": [max_depth], \n",
    "                \"min_sample_split\": [2], \n",
    "                \"f_score\": [f_score], \n",
    "                \"precision\": [precision], \n",
    "                \"recall\": [recall]\n",
    "            })])\n",
    "        \n",
    "        self.__save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainToTrain speichert immer die von einem trainierten DecissionTree verwendeten Feature ab, um in einem kombinierten DecisionTree alle Feature die schon mal verwendet wurden zu verwenden.\n",
    "wichtig: immer die gleichen Train/Test Splits\n",
    "- Optionen:\n",
    "+ testen mit Ausgabe, kein Schreiben: test\n",
    "+ in neue Datei schreiben: newOut\n",
    "+ in default Datei schreiben (nur wenn Ansatz auch gut war): oldOut\n",
    "+ trainieren auf Basis der neuen Feature: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainToTrain:\n",
    "    def __init__(self, pathIn=\"None\", pathOut=\"test\", threshold = 0, paths=\"toTrain\", max_depths=[]):\n",
    "        self.pathOut = pathOut\n",
    "        self.pathIn = pathIn\n",
    "        self.treshold = threshold\n",
    "        self.paths = [os.path.relpath(os.path.join(paths, datei)) for datei in os.listdir(paths) if os.path.isfile(os.path.join(paths, datei))]\n",
    "        self.max_depths = max_depths\n",
    "        self.data = pd.DataFrame(columns=[\"Datei\", \"FeatureList\", \"f_score\", \"precision\", ])\n",
    "    def test(self):\n",
    "        tree = trainMan(self.pathIn)\n",
    "        tree.max_depth(50, 60)\n",
    "        clf = tree.clf\n",
    "        self.__importance(clf, tree.get_X_train)\n",
    "        return self.__getList(clf, tree.get_X_train)\n",
    "    def newOut(self, outPath):\n",
    "        if (self.max_depths == []):\n",
    "            for path in self.paths:\n",
    "                tree = trainMan(path)\n",
    "                depth = tree.max_depth(50, 60)\n",
    "                self.max_depths.append(depth)\n",
    "        i=0\n",
    "        for path in self.paths:\n",
    "            tree = trainMan(path, max_depthVal=self.max_depths[i])\n",
    "            tree.tree()\n",
    "            i+=1\n",
    "            self.data = pd.concat([self.data, pd.DataFrame({\n",
    "                \"Datei\": [path],\n",
    "                \"FeatureList\": [self.__getList(tree.clf, tree.get_X_train)]\n",
    "            })])\n",
    "        self.__save(path=outPath)\n",
    "    def oldOut(self):\n",
    "        if (self.max_depths == []):\n",
    "            for path in self.paths:\n",
    "                tree = trainMan(path)\n",
    "                depth = tree.max_depth(50, 200)\n",
    "                self.max_depths.append(depth)\n",
    "        i=0\n",
    "        for path in self.paths:\n",
    "            tree = trainMan(path, max_depthVal=self.max_depths[i])\n",
    "            tree.tree()\n",
    "            f_score, precision, recall = tree.out()\n",
    "            i+=1\n",
    "            self.data = pd.concat([self.data, pd.DataFrame({\n",
    "                \"Datei\": [path],\n",
    "                \"FeatureList\": [self.__getList(tree.clf, tree.get_X_train)], \n",
    "                \"f_score\": [f_score],\n",
    "                \"precision\": [precision],\n",
    "                \"recall\": [recall]\n",
    "            })])\n",
    "        self.__save()\n",
    "    def __save(self, path=\"ImportanceTrain.csv\"):\n",
    "        self.data.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "        print(\"\\nData gesichert\")\n",
    "    def __importance(self, clf, X_train):\n",
    "        importances = clf.feature_importances_\n",
    "        feature_importances_df = pd.DataFrame({\n",
    "            'Feature': X_train().columns,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        non_zero_importance = feature_importances_df[feature_importances_df['Importance'] > self.treshold]\n",
    "        count_non_zero_importance = non_zero_importance.shape[0]\n",
    "        print(\"Anzahl der Zeilen mit Importanzwerten über \"+str(self.treshold)+\":\", count_non_zero_importance)\n",
    "        top_features = non_zero_importance.head(count_non_zero_importance)\n",
    "        plt.figure(figsize=(10, 40))\n",
    "        sns.barplot(data=top_features, x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n",
    "        plt.title(\"Top Feature Importances\")\n",
    "        plt.xlabel(\"Importance Score\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def __getList(self, clf, X_train):\n",
    "        importances = clf.feature_importances_\n",
    "        feature_importances_df = pd.DataFrame({\n",
    "            'Feature': X_train().columns,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        non_zero_importance = feature_importances_df[feature_importances_df['Importance'] > self.treshold]\n",
    "        count_non_zero_importance = non_zero_importance.shape[0]\n",
    "        top_features = non_zero_importance.head(count_non_zero_importance)\n",
    "        return top_features[\"Feature\"].to_list()\n",
    "    def train(self, inPath = \"ImportanceTrain.csv\"):\n",
    "        df = pd.read_csv(inPath)\n",
    "        df['FeatureList'] = df['FeatureList'].apply(ast.literal_eval) #ast.literal_aval wandelt eine String Liste in eine echte Liste um\n",
    "\n",
    "        datei_feature_liste = df[['Datei', 'FeatureList']].values.tolist() #wandelt DataFrame Zeilen in echte Listen um\n",
    "\n",
    "        erste_features = set(df['FeatureList'].iloc[0])\n",
    "        vergleich = []\n",
    "\n",
    "        for _, features in df.iterrows():\n",
    "            aktuelle_features = set(features['FeatureList'])\n",
    "            \n",
    "            neue_features = aktuelle_features - erste_features\n",
    "            fehlende_features = erste_features - aktuelle_features \n",
    "            \n",
    "            vergleich.append({\n",
    "                'Datei': features['Datei'],\n",
    "                'Neue Features': len(neue_features),\n",
    "                'Fehlende Features': len(fehlende_features)\n",
    "            })\n",
    "\n",
    "        vergleich_df = pd.DataFrame(vergleich)\n",
    "\n",
    "        for datei, features in datei_feature_liste:\n",
    "            print(f\"Datei: {datei}\\nFeatureList: {features}\\n\")\n",
    "        print(\"\\nVergleich:\")\n",
    "        print(vergleich_df)\n",
    "\n",
    "        kombinierte_features = set()\n",
    "        for _, features in datei_feature_liste:\n",
    "            kombinierte_features.update(features)\n",
    "\n",
    "        print(\"\\nKombinierte Features ohne Dopplung:\")\n",
    "        print(kombinierte_features)\n",
    "        print(f\"\\nAnzahl der kombinierten Features: {len(kombinierte_features)}\")\n",
    "        self.__trainCSV(columns = kombinierte_features)\n",
    "    def __trainCSV(self, columns, out_csv=\"combinedFeatures.csv\"):\n",
    "        data = pd.read_csv(\"20 newsgroups/20 newsgroups.csv\", on_bad_lines='skip', sep=';')\n",
    "        data.dropna()\n",
    "        data = data.iloc[:, 1:3]\n",
    "\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        columns = list(columns)\n",
    "        columns.append(\"groupID\")\n",
    "        newFeature = pd.DataFrame(columns=columns)\n",
    "        newFeature.to_csv(out_csv)\n",
    "        i = 0\n",
    "        for index, row in data.iterrows():\n",
    "            text = str(row['text'])\n",
    "            group = str(row['group'])\n",
    "            doc = nlp(text)\n",
    "            count_in_top_1000 = Counter(token.text.lower() for token in doc if token.is_alpha)\n",
    "            haeufigkeiten = {word: count_in_top_1000.get(word, 0) for word in columns}\n",
    "            haeufigkeiten['groupID'] = group\n",
    "            neue_zeile_df = pd.DataFrame([haeufigkeiten])\n",
    "            neue_zeile_df.reset_index(drop=True, inplace=True)\n",
    "            newFeature = pd.concat([newFeature, neue_zeile_df], ignore_index=True)\n",
    "        newFeature.to_csv(out_csv, index=False)\n",
    "        newFeature.head()\n",
    "    def combine_and_train(self):\n",
    "        # Jede Zeile (Datei und Feature-Liste) auslesen\n",
    "        df = pd.read_csv(\"ImportanceTrain.csv\")\n",
    "        df['FeatureList'] = df['FeatureList'].apply(ast.literal_eval)  # String-Liste in echte Liste umwandeln\n",
    "        datei_feature_liste = df[['Datei', 'FeatureList']].values.tolist()\n",
    "\n",
    "        # Alle Kombinationen aus den Listen erstellen\n",
    "        for r in range(1, len(datei_feature_liste) + 1):\n",
    "            for kombination in combinations(datei_feature_liste, r):\n",
    "                kombinierte_features = set()\n",
    "                dateinamen = []\n",
    "\n",
    "                # Features aus der Kombination sammeln\n",
    "                for datei, features in kombination:\n",
    "                    kombinierte_features.update(features)\n",
    "                    dateinamen.append(os.path.basename(datei).replace(\".csv\", \"\"))\n",
    "\n",
    "                # Neuen CSV-Namen erstellen basierend auf der Kombination\n",
    "                neuer_csv_name = \"_\".join(dateinamen) + \".csv\"\n",
    "\n",
    "                # TrainCSV mit kombinierten Features aufrufen\n",
    "                self.__trainCSV(columns=kombinierte_features, out_csv=neuer_csv_name)\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: toTrain\\20newsgroups_processed_1000.csv\n",
      "FeatureList: ['space', 'graphics', 'god', 'thanks', 'orbit', 'religion', 'file', 'bible', 'hi', 'files', 'sky', 'nasa', 'evidence', 'images', 'objective', 'kent', 'people', 'launch', 'disk', 'moon', 'spacecraft', 'jesus', 'islam', 'moral', 'atheist', 'religious', 'image', 'koresh', 'book', 'need', 'card', 'solar', 'program', 'know', 'yes', 'think', 'color', 'atheists', 'time', 'children', 'little', 'islamic', 'algorithm', 'available', 'christian', 'looking', 'points', 'right', 'actually', 'probably', 'y', 'wrong', 'said', 'idea', 'number', 'package', 'christ', 'certainly', 'past', 'flight', 'version', 'use', 'hear', 'remember', 'like', 'truth', 'good', 'sure', 'gamma', 'going', 'different', 'true', 'attempt', 'carry', 'high', 'write', 'agree', 'want', 'system', 'explain', 'able', 'ask', 'groups', 'believe', 'near', 'got', 'claim', 'care', 'order', 'beliefs', 'comes', 'heard', 'low', 'oh', 'guess', 'info', 'posts', 'post', 'makes', 'fire', 'art', 'away', 'technical', 'ftp', 'advance', 'come', 'day', 'definition', 'box', 'etc', 'group', 'argument', 'means', 'word', 'specifically', 'shuttle', 'text', 'called', 'theory', 'mac', 'especially', 'question', 'morality', 'life', 'humans', 'bill', 'person', 'die', 'pay', 'screen', 'government', 'buy', 'type', 'display', 'figure', 'obviously', 'jews', 'action', 'world', 'john', 'fall', 'came', 'z', 'way', 'example', 'planets', 'absolute', 'faith', 'short', 'tell', 'atheism', 'position', 'correct', 'programs', 'easy', 'find', 'interested', 'things', 'check', 'stuff', 'try', 'thought', 'doubt', 'versions', 'better', 'local', 'reading', 'story', 'exist', 'set', 'mean', 'line', 'results', 'faster', 'physics', 'state', 'meaning', 'imaging', 'long', 'point', 'key', 'assume', 'test', 'required', 'happened', 'dead', 'words', 'design', 'found', 'base', 'christians', 'science', 'information', 'model', 'simple', 'complete', 'deleted', 'clearly', 'eternal', 'data', 'reply', 'case', 'form', 'certain', 'opinion', 'years', 'support', 'thing', 'talking', 'recently', 'site', 'fact', 'read', 'c', 'hope', 'self', 'elements', 'cost', 'bit', 'wonder', 'bring', 'sorry', 'half', 'interpretation', 'answer', 'course', 'consider', 'original', 'new', 'night', 'mentioned', 'saying', 'observations', 'numbers', 'actions', 'rest', 'ideas', 'let', 'formats', 'making', 'earlier', 'april', 'xv', 'exists', 'bad', 'sounds', 'capability', 'control', 'moment', 'far', 'today', 'output', 'black', 'american', 'greek', 'mail', 'big', 'exactly', 'structure', 'feel', 'outside', 'false', 'look', 'red', 'valid', 'taking', 'runs', 'took', 'reasonable', 'add', 'knows', 'real', 'belief', 'systems', 'takes', 'cause', 'death', 'completely', 'posting', 'values', 'surface', 'view', 'seeing', 'anti', 'coming', 'entirely', 'report', 'holy', 'g', 'lord', 'tells', 'cheers', 'seen', 'hst', 'human', 'center', 'started', 'according', 'personal', 'defined', 'cross', 'money', 'problem', 'series', 'scientific', 'star', 'merely', 'laws', 'difference', 'months', 'saw', 'tool', 'possibly', 'lost', 'launched', 'pictures', 'thou', 'station', 'problems', 'old', 'written', 'latest', 'faq', 'known', 'working', 'light', 'sense', 'lot', 'maybe', 'objects', 'significant', 'assuming', 'help', 'stage', 'request', 'living', 'gets', 'second', 'sort', 'normal', 'mark', 'p', 'church', 'send', 'change', 'ibm', 'project', 'quote', 'probe', 'nan', 'includes', 'bbs', 'sound', 'sun', 'pc', 'atmosphere', 'street', 'details', 'terms', 'x', 'public', 'running', 'hell', 'email', 'lunar', 'religions', 'office', 'matthew', 'interactive', 'understand', 'ok', 'hardware', 'run', 'rocket', 'lots', 'great', 'jim', 'times', 'result', 'event', 'non', 'bob', 'fine', 'page', 'days', 'reason', 'follow', 'early', 'built', 'spirit', 'needed', 'choice', 'happen', 'effort', 'approach', 'references']\n",
      "\n",
      "Datei: toTrain\\20newsgroups_processed_2000.csv\n",
      "FeatureList: ['space', 'graphics', 'god', 'thanks', 'orbit', 'file', 'religion', 'bible', 'hi', 'nasa', 'images', 'files', 'evidence', 'people', 'kent', 'atheists', 'think', 'objective', 'sky', 'launch', 'spacecraft', 'jesus', 'atheist', 'software', 'moral', 'code', 'solar', 'points', 'moon', 'time', 'children', 'tom', 'religious', 'christian', 'card', 'koresh', 'right', 'comes', 'little', 'islamic', 'looking', 'actually', 'sea', 'certainly', 'ftp', 'yes', 'high', 'christ', 'color', 'claim', 'need', 'image', 'order', 'attempt', 'point', 'number', 'argument', 'islam', 'reason', 'like', 'know', 'called', 'disk', 'death', 'program', 'rest', 'atheism', 'wrong', 'bobby', 'past', 'email', 'true', 'low', 'things', 'book', 'theory', 'cold', 'area', 'word', 'probably', 'moment', 'translation', 'ibm', 'version', 'die', 'rocket', 'good', 'help', 'care', 'discovered', 'u', 'question', 'stuff', 'shuttle', 'thank', 'algorithm', 'mode', 'work', 'working', 'presence', 'costs', 'different', 'field', 'humans', 'check', 'near', 'fire', 'deletion', 'complete', 'days', 'sense', 'makes', 'remember', 'landing', 'jews', 'simple', 'wish', 'ago', 'said', 'sphere', 'screen', 'liquid', 'list', 'test', 'fine', 'features', 'come', 'certain', 'means', 'related', 'try', 'post', 'fair', 'specifically', 'ask', 'knowledge', 'assertion', 'explain', 'talk', 'engineering', 'bill', 'posting', 'going', 'correct', 'programs', 'punishment', 'regards', 'info', 'suggest', 'away', 'species', 'story', 'carry', 'guess', 'difference', 'weather', 'state', 'got', 'happens', 'making', 'killed', 'debate', 'provide', 'computer', 'understand', 'facts', 'happened', 'life', 'heard', 'key', 'eg', 'doubt', 'system', 'site', 'sources', 'thou', 'map', 'weeks', 'look', 'historical', 'concerned', 'stand', 'fail', 'morals', 's', 'assume', 'kill', 'latest', 'clearly', 'straight', 'knowing', 'appears', 'quote', 'anybody', 'sound', 'hello', 'agree', 'necessarily', 'functions', 'maybe', 'editor', 'interpretation', 'lot', 'sin', 'change', 'versions', 'friend', 'sure', 'originally', 'legal', 'guide', 'available', 'drawing', 'satan', 'prove', 'reply', 'closed', 'april', 'better', 'greatly', 'determine', 'christians', 'modern', 'project', 'rational', 'followers', 'flight', 'obviously', 'found', 'fred', 'money', 'came', 'want', 'trying', 'today', 'scientific', 'design', 'allowed', 'lies', 'given', 'outside', 'laws', 'cult', 'sign', 'changes', 'night', 'trouble', 'red', 'ok', 'process', 'involved', 'tell', 'social', 'answer', 'especially', 'position', 'example', 'launched', 'head', 'nice', 'known', 'examples', 'church', 'important', 'understanding', 'arguments', 'buffer', 'welcome', 'gifs', 'newsgroup', 'note', 'works', 'fairly', 'religions', 'thought', 'eternal', 'talking', 'phone', 'idea', 'supports', 'dead', 'handle', 'references', 'love', 'way', 'seeing', 'systems', 'iii', 'earth', 'beliefs', 'consider', 'hear', 'answers', 'amiga', 'receive', 'experience', 'age', 'turn', 'article', 'problem', 'adobe', 'revealed', 'land', 'xv', 'belief', 'years', 'lost', 'hold', 'case', 'getting', 'san', 'reference', 'fall', 'supported', 'planetary', 'save', 'hardware', 'worth', 'groups', 'behavior', 'admit', 'force', 'supply', 'date', 'let', 'read', 'unto', 'total', 'assumption', 'gods', 'spirit', 'government', 'day', 'hole', 'structure', 'distance', 'course', 'times', 'purpose', 'bits', 'hope', 'text', 'contradictions', 'p', 'looks', 'requires', 'thousands', 'apparently', 'seconds', 'form', 'matters', 'possible', 'report', 'old', 'seriously', 'bad', 'find', 'eventually', 'star', 'views', 'robert', 'justify', 'interested', 'ones', 'reach', 'new', 'seen', 'john', 'christianity', 'mail', 'responses', 'support', 'texts', 'satellites', 'budget', 'necessary', 'lots', 'collection', 'road', 'deleted', 'posts', 'faq', 'tool', 'sounds', 'send', 'needed', 'jewish', 'natural', 'subject', 'original', 'circle', 'entire', 'knows', 'bit', 'observer', 'value', 'etc']\n",
      "\n",
      "Datei: toTrain\\20newsgroups_processed_3000.csv\n",
      "FeatureList: ['space', 'graphics', 'god', 'thanks', 'orbit', 'religion', 'file', 'bible', 'hi', 'nasa', 'images', 'files', 'evidence', 'kent', 'atheists', 'objective', 'sky', 'launch', 'spacecraft', 'jesus', 'think', 'people', 'software', 'points', 'moral', 'solar', 'religious', 'like', 'atheist', 'code', 'moon', 'know', 'tom', 'email', 'card', 'islamic', 'christ', 'koresh', 'children', 'little', 'looking', 'order', 'book', 'sea', 'certainly', 'ftp', 'christian', 'attempt', 'comes', 'high', 'believe', 'image', 'probably', 'time', 'yes', 'means', 'right', 'number', 'come', 'need', 'actually', 'different', 'built', 'following', 'color', 'disk', 'program', 'way', 'death', 'islam', 'past', 'claim', 'good', 'bobby', 'low', 'sure', 'christians', 'killed', 'things', 'area', 'fire', 'translation', 'heard', 'ibm', 'find', 'version', 'life', 'die', 'reason', 'wrong', 'rocket', 'old', 'material', 'sense', 'care', 'read', 'evening', 'discovered', 'u', 'theory', 'days', 'appreciate', 'better', 'ago', 'shuttle', 'thank', 'algorithm', 'mode', 'argument', 'running', 'work', 'said', 'allen', 'field', 'humans', 'near', 'help', 'going', 'true', 'post', 'makes', 'jews', 'simple', 'landing', 'false', 'deleted', 'sources', 'related', 'fair', 'fact', 'define', 'specifically', 'cold', 'look', 'assertion', 'engineering', 'posting', 'believes', 'happened', 'years', 'course', 'steve', 'punishment', 'want', 'suggest', 'question', 'away', 'species', 'belief', 'having', 'carry', 'bill', 'satan', 'beliefs', 'word', 'clearly', 'weather', 'stuff', 'appreciated', 'making', 'reaction', 'money', 'online', 'sin', 'article', 'regards', 'try', 'fish', 'orbital', 'system', 'state', 'screen', 'maybe', 'bring', 'et', 'decent', 'tree', 'concerned', 'test', 'philosophy', 'pointed', 'drawing', 'map', 'lights', 'real', 'allowed', 'complete', 's', 'save', 'send', 'md', 'articles', 'certain', 'sounds', 'sorts', 'home', 'hear', 'problems', 'oh', 'great', 'efficient', 'new', 'times', 'editor', 'interpretation', 'lot', 'verse', 'g', 'soon', 'grand', 'kill', 'format', 'tell', 'sorry', 'closely', 'hello', 'y', 'pov', 'etc', 'review', 'today', 'sign', 'correct', 'features', 'talk', 'followers', 'ignorant', 'earlier', 'obviously', 'mistaken', 'thought', 'luck', 'checked', 'sins', 'books', 'april', 'option', 'complicated', 'ones', 'flight', 'man', 'physics', 'site', 'school', 'modern', 'mean', 'known', 'hot', 'assumption', 'blue', 'supposed', 'numbers', 'buy', 'term', 'especially', 'instead', 'double', 'asking', 'absolute', 'noticed', 'copy', 'recently', 'earth', 'guide', 'point', 'laws', 'moment', 'throw', 'pain', 'thing', 'semi', 'explain', 'highly', 'hardware', 'example', 'reported', 'straight', 'eternal', 'theists', 'deletion', 'receive', 'short', 'check', 'gain', 'love', 'statements', 'population', 'admit', 'available', 'research', 'open', 'behavior', 'difference', 'fred', 'rational', 'eye', 'writes', 'postings', 'rest', 'revealed', 'lord', 'ignorance', 'design', 'let', 'seeing', 'mary', 'apply', 'stand', 'tax', 'middle', 'creating', 'placed', 'passed', 'info', 'mother', 'began', 'guess', 'interesting', 'took', 'recall', 'idea', 'correctly', 'second', 'clouds', 'changed', 'issues', 'answer', 'cost', 'flying', 'free', 'sun', 'fix', 'founded', 'previous', 'san', 'mass', 'instruments', 'talking', 'disagree', 'writings', 'got', 'provide', 'called', 'stick', 'possible', 'geometric', 'random', 'involved', 'avenue', 'consider', 'date', 'display', 'finally', 'far', 'fill', 'examples', 'centuries', 'issue', 'comments', 'difficult', 'instance', 'speak', 'thread', 'text', 'church', 'proton', 'religions', 'country', 'bright', 'john', 'late', 'iii', 'day', 'given', 'larger', 'texts', 'law', 'particle', 'age', 'interest', 'responses', 'mail', 'able', 'early', 'world', 'fight', 'technology', 'write', 'guy', 'anti', 'gets', 'interested', 'released', 'congress', 'problem', 'c', 'stage', 'technical', 'tool', 'influence', 'amazing', 'access', 'slightly', 'message', 'showing', 'kind', 'updated', 'systems', 'correction', 'asked', 'plenty', 'wondering', 'phone', 'developed', 'original', 'naturally', 'realistic', 'form', 'illinois']\n",
      "\n",
      "\n",
      "Vergleich:\n",
      "                                     Datei  Neue Features  Fehlende Features\n",
      "0  toTrain\\20newsgroups_processed_1000.csv              0                  0\n",
      "1  toTrain\\20newsgroups_processed_2000.csv            166                165\n",
      "2  toTrain\\20newsgroups_processed_3000.csv            202                179\n",
      "\n",
      "Kombinierte Features ohne Dopplung:\n",
      "{'model', 'engineering', 'results', 'sign', 'clearly', 'instruments', 'exactly', 'etc', 'guy', 'founded', 'pay', 'cheers', 'texts', 'absolute', 'numbers', 'ftp', 'word', 'pointed', 'obviously', 'anti', 'moon', 'world', 'physics', 'works', 'bbs', 'thousands', 'proton', 'subject', 'computer', 'interest', 'material', 'bits', 'getting', 'articles', 'disagree', 'programs', 'allowed', 'lights', 'ones', 'thou', 'understand', 'hope', 'formats', 'send', 'office', 'term', 'effort', 'version', 'books', 'sun', 'closely', 'shuttle', 'jews', 'meaning', 'laws', 'stand', 'having', 'efficient', 'atmosphere', 'previous', 'atheists', 'report', 'congress', 'soon', 'related', 'sorts', 'code', 'got', 'greek', 'asking', 'complete', 'advance', 'matthew', 'guess', 'total', 'day', 'base', 'hole', 'new', 'result', 'graphics', 'sins', 'feel', 'issue', 'sort', 'email', 'influence', 'years', 'site', 'test', 'entirely', 'moral', 'knowing', 'thread', 'scientific', 'creating', 'normal', 'determine', 'man', 'significant', 'morals', 'information', 'completely', 'historical', 'population', 'purpose', 'low', 'money', 'circle', 'lunar', 'list', 'head', 'belief', 'series', 'thing', 'case', 'z', 'elements', 'points', 'set', 'p', 'doubt', 'number', 'saw', 'pictures', 'maybe', 'middle', 'objective', 'oh', 'april', 'fix', 'planetary', 'deletion', 'references', 'add', 'handle', 'valid', 'reason', 'article', 'means', 'today', 'trying', 's', 'interesting', 'like', 'avenue', 'fish', 'naturally', 'bill', 'probe', 'steve', 'fine', 'luck', 'assume', 'suggest', 'human', 'thanks', 'work', 'box', 'features', 'approach', 'values', 'difficult', 'developed', 'early', 'program', 'probably', 'religion', 'fire', 'problem', 'jewish', 'question', 'decent', 'state', 'near', 'supposed', 'double', 'real', 'event', 'atheist', 'y', 'data', 'costs', 'post', 'koresh', 'non', 'station', 'correction', 'software', 'happens', 'wondering', 'greatly', 'religious', 'true', 'old', 'art', 'orbit', 'anybody', 'earth', 'fail', 'random', 'said', 'image', 'showing', 'sure', 'important', 'option', 'working', 'md', 'reading', 'atheism', 'cult', 'person', 'want', 'long', 'seriously', 'think', 'god', 'eye', 'sense', 'file', 'output', 'ago', 'posting', 'supply', 'satellites', 'flying', 'assertion', 'imaging', 'age', 'hot', 'false', 'justify', 'appreciated', 'actually', 'spirit', 'et', 'bob', 'kill', 'orbital', 'legal', 'home', 'structure', 'seen', 'plenty', 'asked', 'g', 'budget', 'things', 'follow', 'noticed', 'sea', 'life', 'objects', 'mac', 'required', 'appears', 'page', 'screen', 'children', 'interested', 'original', 'different', 'cross', 'ok', 'takes', 'street', 'gets', 'look', 'date', 'night', 'force', 'certainly', 'phone', 'recall', 'speak', 'nan', 'point', 'assumption', 'islam', 'makes', 'rocket', 'format', 'running', 'receive', 'mass', 'reported', 'exists', 'thought', 'guide', 'need', 'necessary', 'arguments', 'theory', 'illinois', 'star', 'ignorant', 'fairly', 'possibly', 'cost', 'sorry', 'lots', 'mode', 'began', 'card', 'seeing', 'specifically', 'answer', 'mark', 'started', 'correct', 'faster', 'experience', 'mistaken', 'discovered', 'gain', 'lord', 'natural', 'free', 'death', 'supports', 'argument', 'run', 'san', 'science', 'form', 'according', 'beliefs', 'land', 'functions', 'reach', 'turn', 'came', 'cause', 'found', 'love', 'great', 'recently', 'ibm', 'sphere', 'good', 'coming', 'reaction', 'behavior', 'map', 'let', 'attempt', 'fair', 'actions', 'launch', 'type', 'worth', 'control', 'truth', 'postings', 'fight', 'friend', 'supported', 'believes', 'able', 'facts', 'closed', 'editor', 'reference', 'translation', 'grand', 'easy', 'fact', 'hst', 'kent', 'talk', 'available', 'social', 'difference', 'x', 'apply', 'christian', 'weeks', 'eventually', 'files', 'people', 'rational', 'taking', 'called', 'book', 'info', 'order', 'local', 'semi', 'problems', 'way', 'idea', 'religions', 'care', 'known', 'originally', 'planets', 'months', 'surface', 'tom', 'gamma', 'moment', 'days', 'killed', 'right', 'sources', 'slightly', 'u', 'apparently', 'package', 'action', 'black', 'pc', 'field', 'straight', 'hardware', 'eg', 'nasa', 'carry', 'big', 'time', 'country', 'robert', 'self', 'check', 'larger', 'bobby', 'weather', 'sounds', 'kind', 'especially', 'disk', 'following', 'past', 'know', 'system', 'text', 'light', 'drawing', 'updated', 'ideas', 'satan', 'clouds', 'high', 'gods', 'centuries', 'amiga', 'making', 'knows', 'throw', 'posts', 'buffer', 'answers', 'half', 'agree', 'sound', 'humans', 'fred', 'jesus', 'find', 'merely', 'punishment', 'happened', 'access', 'passed', 'happen', 'capability', 'liquid', 'ignorance', 'particle', 'adobe', 'personal', 'government', 'definition', 'position', 'deleted', 'tool', 'knowledge', 'concerned', 'versions', 'xv', 'example', 'pain', 'writings', 'solar', 'gifs', 'distance', 'verse', 'instance', 'use', 'come', 'newsgroup', 'released', 'provide', 'interactive', 'interpretation', 'regards', 'figure', 'includes', 'issues', 'contradictions', 'mean', 'saying', 'church', 'yes', 'followers', 'consider', 'faith', 'bit', 'opinion', 'road', 'hold', 'claim', 'unto', 'certain', 'key', 'course', 'tell', 'quote', 'involved', 'explain', 'thank', 'iii', 'lot', 'bad', 'going', 'living', 'define', 'technology', 'change', 'instead', 'late', 'hi', 'eternal', 'necessarily', 'wonder', 'presence', 'hello', 'talking', 'terms', 'mentioned', 'buy', 'fall', 'details', 'comes', 'times', 'nice', 'value', 'appreciate', 'mail', 'exist', 'view', 'revealed', 'placed', 'little', 'wrong', 'mary', 'stage', 'online', 'away', 'short', 'school', 'space', 'responses', 'research', 'statements', 'wish', 'entire', 'written', 'sin', 'collection', 'better', 'holy', 'trouble', 'correctly', 'simple', 'possible', 'pov', 'reply', 'dead', 'die', 'took', 'theists', 'help', 'read', 'faq', 'algorithm', 'message', 'looking', 'changes', 'realistic', 'understanding', 'flight', 'red', 'stuff', 'rest', 'systems', 'highly', 'group', 'fill', 'c', 'christ', 'runs', 'admit', 'reasonable', 'far', 'landing', 'allen', 'line', 'evening', 'words', 'mother', 'request', 'public', 'open', 'assuming', 'views', 'seconds', 'display', 'groups', 'geometric', 'debate', 'spacecraft', 'welcome', 'finally', 'species', 'hell', 'observer', 'islamic', 'requires', 'choice', 'tree', 'philosophy', 'try', 'prove', 'story', 'checked', 'copy', 'john', 'support', 'latest', 'technical', 'evidence', 'bring', 'matters', 'complicated', 'modern', 'cold', 'american', 'lies', 'images', 'ask', 'note', 'second', 'center', 'morality', 'sky', 'remember', 'color', 'needed', 'project', 'defined', 'built', 'area', 'write', 'review', 'tax', 'tells', 'christianity', 'comments', 'heard', 'examples', 'amazing', 'lost', 'process', 'save', 'observations', 'jim', 'bright', 'given', 'blue', 'launched', 'looks', 'earlier', 'law', 'writes', 'design', 'bible', 'believe', 'hear', 'changed', 'outside', 'christians', 'stick'}\n",
      "\n",
      "Anzahl der kombinierten Features: 694\n"
     ]
    }
   ],
   "source": [
    "test2 = trainToTrain()\n",
    "#test2.oldOut()\n",
    "test2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6182263247464747, 0.6148219505969806, 0.6574136289648552)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = trainMan(path=\"combinedFeatures.csv\")\n",
    "print(new.max_depth(1, 200))\n",
    "new.out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideen:\n",
    "- manuelles Auswählen indem man durch die csv gehen kann und immer sagen ob man die Feature Liste will oder nicht\n",
    "- automatisches Optimieren duch alle Kombinationen an Feature Listen\n",
    "- Durch die Urpsurngsdatei gehen und schauen wie viele Feature auf die jeweilige Zeile zutreffen, wenn es in einer Zeile zu wenig sind wird diese vermerkt um die Feature Auswahl zu optimieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processor: \n",
    "- notwendiger Schritt beim Arbeiten mit einen kombinierten Feature Liste, es muss sicher gestellt werden das keine Testdaten schon für das Training verwendet werden.\n",
    "- gibt 3 csv Datein zurück: die Ursprüngliche, die Trainingsdaten und die Testdaten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiumKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
